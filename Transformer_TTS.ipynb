{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f559f9e4",
      "metadata": {
        "id": "f559f9e4"
      },
      "source": [
        "Transformers in Text-to-Speech\n",
        "\n",
        "=====================================================\n",
        "\n",
        "## Introduction\n",
        "---------------\n",
        "\n",
        "Transformers have revolutionized the field of natural language processing (NLP) with their ability to handle sequential data efficiently. In recent years, researchers have applied Transformer architecture to text-to-speech (TTS) synthesis, achieving impressive results. This project focuses on the application and implementation of Transformers in TTS systems.\n",
        "\n",
        "## Background\n",
        "-------------\n",
        "\n",
        "Traditional TTS systems relied on concatenative synthesis, statistical parametric synthesis, and waveform modeling. However, these approaches have limitations, such as requiring large amounts of data and being prone to over-smoothing. The introduction of deep learning techniques, particularly Transformers, has improved TTS performance significantly.\n",
        "\n",
        "## Transformer-based TTS\n",
        "-------------------------\n",
        "\n",
        "The Transformer architecture, introduced by Vaswani et al. (2017) [1], is well-suited for sequence-to-sequence tasks, making it an ideal choice for TTS. The self-attention mechanism in Transformers enables the model to capture long-range dependencies in input sequences, which is essential for generating coherent and natural-sounding speech.\n",
        "\n",
        "One of the pioneering works in Transformer-based TTS is the Transformer TTS (T-TTS) model proposed by Li et al. (2019) [2]. This model utilizes a Transformer encoder to process input text and a decoder to generate mel-spectrograms. The authors demonstrated that T-TTS outperforms traditional TTS systems in terms of naturalness and intelligibility.\n",
        "\n",
        "## Advancements and Variants\n",
        "-----------------------------\n",
        "\n",
        "Several variants of Transformer-based TTS models have been proposed to improve performance and efficiency, we will extensively use part of Fastspeech from Speechbrain and HiFi-GAN for our vocoder:\n",
        "\n",
        "### FastSpeech\n",
        "\n",
        "Ren et al. (2020) [3] proposed FastSpeech, a parallelizable, lightweight architecture that reduces computational complexity while maintaining performance.\n",
        "\n",
        "### HiFi-GAN\n",
        "\n",
        "Kong et al. (2020) [4] introduced HiFi-GAN, which employs a Generative Adversarial Network (GAN) to improve the quality of generated speech, achieving state-of-the-art results.\n",
        "\n",
        "### Conformer\n",
        "\n",
        "Gulati et al. (2020) [5] proposed Conformer, an architecture that integrates convolutional and self-attention mechanisms to capture both local and global dependencies in input sequences.\n",
        "\n",
        "## Challenges and Future Directions\n",
        "---------------------------------\n",
        "\n",
        "Despite the success of Transformer-based TTS models, there are still challenges to be addressed:\n",
        "\n",
        "### Over-smoothing\n",
        "\n",
        "Transformers can suffer from over-smoothing, leading to a lack of expressiveness in generated speech.\n",
        "\n",
        "### Data scarcity\n",
        "\n",
        "Limited availability of high-quality, diverse speech datasets hinders the training of robust TTS models.\n",
        "\n",
        "### Multimodal fusion\n",
        "\n",
        "Integrating visual and linguistic information to generate more realistic and engaging speech synthesis.\n",
        "\n",
        "## Technical Reference\n",
        "----------\n",
        "All the Technical reference, inspiration and guidance had been majorly implemted with the help of speechbrain project[6] and Trasnformer-TTS by Soobinseo[7].\n",
        "\n",
        "## Conclusion\n",
        "----------\n",
        "\n",
        "Transformer-based TTS models have revolutionized the field of speech synthesis, offering improved performance, efficiency, and flexibility. The proposed project aims to implement a Transformer TTS model using SpeechBrain, a popular open-source toolkit for speech and language processing. By leveraging the strengths of Transformers, the project aims to create a high-quality TTS system that can generate natural-sounding speech.\n",
        "\n",
        "## References\n",
        "--------------\n",
        "\n",
        "[1] Vaswani et al. (2017). Attention is All You Need. In Advances in Neural Information Processing Systems (NIPS 2017).\n",
        "\n",
        "[2] Li et al. (2019). Neural Speech Synthesis with Transformer Network. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics.\n",
        "\n",
        "[3] Ren et al. (2020). FastSpeech: Fast, Robust and Controllable Text to Speech. In Advances in Neural Information Processing Systems (NIPS 2020).\n",
        "\n",
        "[4] Kong et al. (2020). HiFi-GAN: Generative Adversarial Networks for Hi-Fi Speech Synthesis. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.\n",
        "\n",
        "[5] Gulati et al. (2020). Conformer: Convolution-augmented Transformer for Speech Synthesis. In Proceedings of the 2020 IEEE International Conference on Acoustics, Speech and Signal Processing.\n",
        "\n",
        "[6] M. Ravanelli et al., ‘SpeechBrain: A General-Purpose Speech Toolkit’, arXiv [eess.AS]. 2021.\n",
        "\n",
        "[7] Soobinseo. (n.d.). GitHub - soobinseo/Transformer-TTS: A Pytorch Implementation of “Neural Speech Synthesis with Transformer Network.” GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30112731",
      "metadata": {
        "id": "30112731"
      },
      "source": [
        "##Project Begning - Training\n",
        "\n",
        "The code cell below consists of two commands using pip and gdown:\n",
        "\n",
        "1. `!pip install --upgrade --no-cache-dir gdown`: This command uses pip to install or upgrade the `gdown` package without caching any downloaded files. The `--upgrade` flag ensures that if `gdown` is already installed, it will be upgraded to the latest version. `--no-cache-dir` flag disables caching of downloaded files, which can save disk space.\n",
        "   \n",
        "2. `!gdown 1u28CGvLBQAVj4oHqe7l4oPNvsswAIFO3`: This command uses `gdown` to download a file from Google Drive. The file is identified by the ID `1u28CGvLBQAVj4oHqe7l4oPNvsswAIFO3`. This specific file appears to be related to the LibriSpeech dataset.\n",
        "\n",
        "3. `%%capture`: This magic command captures the output of the cell and prevents it from being displayed in the notebook. It's often used when you don't want to display the output of a specific cell.\n",
        "\n",
        "4. `!unzip LJSpeech-1.1.zip -d data`: This shell command unzips the file `LJSpeech-1.1.zip` and extracts its contents into a directory named `data`. The `-d` flag specifies the destination directory for the extracted files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8bYoEiboqIBV",
      "metadata": {
        "id": "8bYoEiboqIBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcc6a04-29a1-430f-8d01-508f44ba5da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/760.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/760.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m583.7/760.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
            "Installing collected packages: ruamel.yaml.clib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 speechbrain-1.0.0\n",
            "Collecting tgt\n",
            "  Downloading tgt-1.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tgt\n",
            "Successfully installed tgt-1.5\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml) (6.0.1)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml) (0.18.6)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml) (0.2.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain\n",
        "!pip install tgt\n",
        "!pip install unidecode\n",
        "!pip install hyperpyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "M0V3wrqopz9N",
      "metadata": {
        "id": "M0V3wrqopz9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386b57dc-f68c-4b21-f7d9-176439067d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1u28CGvLBQAVj4oHqe7l4oPNvsswAIFO3\n",
            "From (redirected): https://drive.google.com/uc?id=1u28CGvLBQAVj4oHqe7l4oPNvsswAIFO3&confirm=t&uuid=8b936d17-dfc6-4a77-930e-90516e3bedf8\n",
            "To: /content/LJSpeech-1.1.zip\n",
            "100% 415M/415M [00:04<00:00, 103MB/s] \n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown 1u28CGvLBQAVj4oHqe7l4oPNvsswAIFO3 ## Librispeech subset of Dataset to speedily check things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2Ka15oDcp1B-",
      "metadata": {
        "id": "2Ka15oDcp1B-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip LJSpeech-1.1.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Inspired by Speechbrain Fastspeech)\n",
        "\n",
        "This Python code is used to prepare the LJ Speech dataset for use in training models for speech synthesis tasks. It involves tasks such as:\n",
        "\n",
        "1. Splitting the dataset into training, validation, and test sets.\n",
        "2. Generating JSON files containing information about audio files, their corresponding transcriptions, and optionally, additional data like phoneme alignments and pitch information.\n",
        "3. Optionally computing phoneme alignments and pitch values for models that require such data, like FastSpeech2 but we will not be using the parts and for their generation.\n",
        "4. Cleaning and preprocessing text data.\n",
        "5. Ensuring reproducibility by setting random seeds and checking if the data preparation phase has been completed before.\n",
        "6. Logging progress and errors during the preparation process."
      ],
      "metadata": {
        "id": "U64tgOorqvx_"
      },
      "id": "U64tgOorqvx_"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "255b5830",
      "metadata": {
        "id": "255b5830"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from speechbrain.utils.data_utils import download_file\n",
        "from speechbrain.dataio.dataio import load_pkl, save_pkl\n",
        "import tgt\n",
        "from speechbrain.inference.text import GraphemeToPhoneme\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from speechbrain.utils.text_to_sequence import _g2p_keep_punctuations\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "OPT_FILE = \"opt_ljspeech_prepare.pkl\"\n",
        "METADATA_CSV = \"metadata.csv\"\n",
        "TRAIN_JSON = \"train.json\"\n",
        "VALID_JSON = \"valid.json\"\n",
        "TEST_JSON = \"test.json\"\n",
        "WAVS = \"wavs\"\n",
        "DURATIONS = \"durations\"\n",
        "\n",
        "def prepare_ljspeech(\n",
        "    data_folder,\n",
        "    save_folder,\n",
        "    splits=[\"train\", \"valid\"],\n",
        "    split_ratio=[90, 10],\n",
        "    model_name=None,\n",
        "    seed=1234,\n",
        "    pitch_n_fft=1024,\n",
        "    pitch_hop_length=256,\n",
        "    pitch_min_f0=65,\n",
        "    pitch_max_f0=400,\n",
        "    skip_prep=False,\n",
        "    use_custom_cleaner=False,\n",
        "    device=\"cpu\",\n",
        "):\n",
        "\n",
        "    random.seed(seed)\n",
        "\n",
        "    if skip_prep:\n",
        "        return\n",
        "\n",
        "    conf = {\n",
        "        \"data_folder\": data_folder,\n",
        "        \"splits\": splits,\n",
        "        \"split_ratio\": split_ratio,\n",
        "        \"save_folder\": save_folder,\n",
        "        \"seed\": seed,\n",
        "    }\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    meta_csv = os.path.join(data_folder, METADATA_CSV)\n",
        "    wavs_folder = os.path.join(data_folder, WAVS)\n",
        "\n",
        "    save_opt = os.path.join(save_folder, OPT_FILE)\n",
        "    save_json_train = os.path.join(save_folder, TRAIN_JSON)\n",
        "    save_json_valid = os.path.join(save_folder, VALID_JSON)\n",
        "    save_json_test = os.path.join(save_folder, TEST_JSON)\n",
        "\n",
        "    phoneme_alignments_folder = None\n",
        "    duration_folder = None\n",
        "    pitch_folder = None\n",
        "    if model_name is not None and \"FastSpeech2\" in model_name:\n",
        "        alignment_URL = (\n",
        "            \"https://www.dropbox.com/s/v28x5ldqqa288pu/LJSpeech.zip?dl=1\"\n",
        "        )\n",
        "        phoneme_alignments_folder = os.path.join(\n",
        "            data_folder, \"TextGrid\", \"LJSpeech\"\n",
        "        )\n",
        "        download_file(\n",
        "            alignment_URL, data_folder + \"/alignments.zip\", unpack=True\n",
        "        )\n",
        "\n",
        "        duration_folder = os.path.join(data_folder, \"durations\")\n",
        "        if not os.path.exists(duration_folder):\n",
        "            os.makedirs(duration_folder)\n",
        "\n",
        "        pitch_folder = os.path.join(data_folder, \"pitch\")\n",
        "        if not os.path.exists(pitch_folder):\n",
        "            os.makedirs(pitch_folder)\n",
        "\n",
        "    if skip(splits, save_folder, conf):\n",
        "        logger.info(\"Skipping preparation, completed in previous run.\")\n",
        "        return\n",
        "\n",
        "    assert os.path.exists(meta_csv), \"metadata.csv does not exist\"\n",
        "    assert os.path.exists(wavs_folder), \"wavs/ folder does not exist\"\n",
        "\n",
        "    msg = \"Creating json file for ljspeech Dataset..\"\n",
        "    logger.info(msg)\n",
        "    data_split, meta_csv = split_sets(data_folder, splits, split_ratio)\n",
        "\n",
        "    if \"train\" in splits:\n",
        "        prepare_json(\n",
        "            model_name,\n",
        "            data_split[\"train\"],\n",
        "            save_json_train,\n",
        "            wavs_folder,\n",
        "            meta_csv,\n",
        "            phoneme_alignments_folder,\n",
        "            duration_folder,\n",
        "            pitch_folder,\n",
        "            pitch_n_fft,\n",
        "            pitch_hop_length,\n",
        "            pitch_min_f0,\n",
        "            pitch_max_f0,\n",
        "            use_custom_cleaner,\n",
        "            device,\n",
        "        )\n",
        "    if \"valid\" in splits:\n",
        "        prepare_json(\n",
        "            model_name,\n",
        "            data_split[\"valid\"],\n",
        "            save_json_valid,\n",
        "            wavs_folder,\n",
        "            meta_csv,\n",
        "            phoneme_alignments_folder,\n",
        "            duration_folder,\n",
        "            pitch_folder,\n",
        "            pitch_n_fft,\n",
        "            pitch_hop_length,\n",
        "            pitch_min_f0,\n",
        "            pitch_max_f0,\n",
        "            use_custom_cleaner,\n",
        "            device,\n",
        "        )\n",
        "    if \"test\" in splits:\n",
        "        prepare_json(\n",
        "            model_name,\n",
        "            data_split[\"test\"],\n",
        "            save_json_test,\n",
        "            wavs_folder,\n",
        "            meta_csv,\n",
        "            phoneme_alignments_folder,\n",
        "            duration_folder,\n",
        "            pitch_folder,\n",
        "            pitch_n_fft,\n",
        "            pitch_hop_length,\n",
        "            pitch_min_f0,\n",
        "            pitch_max_f0,\n",
        "            use_custom_cleaner,\n",
        "            device,\n",
        "        )\n",
        "    save_pkl(conf, save_opt)\n",
        "\n",
        "\n",
        "def skip(splits, save_folder, conf):\n",
        "\n",
        "    skip = True\n",
        "\n",
        "    split_files = {\n",
        "        \"train\": TRAIN_JSON,\n",
        "        \"valid\": VALID_JSON,\n",
        "        \"test\": TEST_JSON,\n",
        "    }\n",
        "\n",
        "    for split in splits:\n",
        "        if not os.path.isfile(os.path.join(save_folder, split_files[split])):\n",
        "            skip = False\n",
        "\n",
        "    save_opt = os.path.join(save_folder, OPT_FILE)\n",
        "    if skip is True:\n",
        "        if os.path.isfile(save_opt):\n",
        "            opts_old = load_pkl(save_opt)\n",
        "            if opts_old == conf:\n",
        "                skip = True\n",
        "            else:\n",
        "                skip = False\n",
        "        else:\n",
        "            skip = False\n",
        "    return skip\n",
        "\n",
        "\n",
        "def split_sets(data_folder, splits, split_ratio):\n",
        "\n",
        "    meta_csv = os.path.join(data_folder, METADATA_CSV)\n",
        "    with open(meta_csv, 'r', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(\n",
        "           csvfile, delimiter=\"|\", quoting=csv.QUOTE_NONE\n",
        "        )\n",
        "\n",
        "        meta_csv = list(csv_reader)\n",
        "\n",
        "        index_for_sessions = []\n",
        "        session_id_start = \"LJ001\"\n",
        "        index_this_session = []\n",
        "        for i in range(len(meta_csv)):\n",
        "            session_id = meta_csv[i][0].split(\"-\")[0]\n",
        "            if session_id == session_id_start:\n",
        "                index_this_session.append(i)\n",
        "                if i == len(meta_csv) - 1:\n",
        "                    index_for_sessions.append(index_this_session)\n",
        "            else:\n",
        "                index_for_sessions.append(index_this_session)\n",
        "                session_id_start = session_id\n",
        "                index_this_session = [i]\n",
        "\n",
        "        session_len = [len(session) for session in index_for_sessions]\n",
        "\n",
        "        data_split = {}\n",
        "        for i, split in enumerate(splits):\n",
        "            data_split[split] = []\n",
        "            for j in range(len(index_for_sessions)):\n",
        "                if split == \"train\":\n",
        "                    random.shuffle(index_for_sessions[j])\n",
        "                    n_snts = int(session_len[j] * split_ratio[i] / sum(split_ratio))\n",
        "                    data_split[split].extend(index_for_sessions[j][0:n_snts])\n",
        "                    del index_for_sessions[j][0:n_snts]\n",
        "                if split == \"valid\":\n",
        "                    if \"test\" in splits:\n",
        "                        random.shuffle(index_for_sessions[j])\n",
        "                        n_snts = int(\n",
        "                            session_len[j] * split_ratio[i] / sum(split_ratio)\n",
        "                        )\n",
        "                        data_split[split].extend(index_for_sessions[j][0:n_snts])\n",
        "                        del index_for_sessions[j][0:n_snts]\n",
        "                    else:\n",
        "                        data_split[split].extend(index_for_sessions[j])\n",
        "                if split == \"test\":\n",
        "                    data_split[split].extend(index_for_sessions[j])\n",
        "\n",
        "    return data_split, meta_csv\n",
        "\n",
        "\n",
        "def prepare_json(\n",
        "    model_name,\n",
        "    seg_lst,\n",
        "    json_file,\n",
        "    wavs_folder,\n",
        "    csv_reader,\n",
        "    phoneme_alignments_folder,\n",
        "    durations_folder,\n",
        "    pitch_folder,\n",
        "    pitch_n_fft,\n",
        "    pitch_hop_length,\n",
        "    pitch_min_f0,\n",
        "    pitch_max_f0,\n",
        "    use_custom_cleaner=False,\n",
        "    device=\"cpu\",\n",
        "):\n",
        "\n",
        "    logger.info(f\"preparing {json_file}.\")\n",
        "    if model_name in [\"Tacotron2\", \"FastSpeech2\"]:\n",
        "        logger.info(\n",
        "            \"Computing phonemes for LJSpeech labels using SpeechBrain G2P. This may take a while.\"\n",
        "        )\n",
        "        g2p = GraphemeToPhoneme.from_hparams(\n",
        "            \"speechbrain/soundchoice-g2p\", run_opts={\"device\": device}\n",
        "        )\n",
        "    if model_name is not None and \"FastSpeech2\" in model_name:\n",
        "        logger.info(\n",
        "            \"Computing pitch as required for FastSpeech2. This may take a while.\"\n",
        "        )\n",
        "\n",
        "    json_dict = {}\n",
        "    for index in tqdm(seg_lst):\n",
        "        id = list(csv_reader)[index][0]\n",
        "        wav = os.path.join(wavs_folder, f\"{id}.wav\")\n",
        "        label = list(csv_reader)[index][2]\n",
        "        if use_custom_cleaner:\n",
        "            label = custom_clean(label, model_name)\n",
        "\n",
        "        json_dict[id] = {\n",
        "            \"uttid\": id,\n",
        "            \"wav\": wav,\n",
        "            \"label\": label,\n",
        "            \"segment\": True if \"train\" in json_file else False,\n",
        "        }\n",
        "\n",
        "        if model_name == \"FastSpeech2\":\n",
        "            audio, fs = torchaudio.load(wav)\n",
        "\n",
        "            textgrid_path = os.path.join(\n",
        "                phoneme_alignments_folder, f\"{id}.TextGrid\"\n",
        "            )\n",
        "            textgrid = tgt.io.read_textgrid(\n",
        "                textgrid_path, include_empty_intervals=True\n",
        "            )\n",
        "\n",
        "            last_phoneme_flags = get_last_phoneme_info(\n",
        "                textgrid.get_tier_by_name(\"words\"),\n",
        "                textgrid.get_tier_by_name(\"phones\"),\n",
        "            )\n",
        "            (\n",
        "                phonemes,\n",
        "                duration,\n",
        "                start,\n",
        "                end,\n",
        "                trimmed_last_phoneme_flags,\n",
        "            ) = get_alignment(\n",
        "                textgrid.get_tier_by_name(\"phones\"),\n",
        "                fs,\n",
        "                pitch_hop_length,\n",
        "                last_phoneme_flags,\n",
        "            )\n",
        "\n",
        "            label_phoneme = \" \".join(phonemes)\n",
        "            spn_labels = [0] * len(phonemes)\n",
        "            for i in range(1, len(phonemes)):\n",
        "                if phonemes[i] == \"spn\":\n",
        "                    spn_labels[i - 1] = 1\n",
        "            if start >= end:\n",
        "                print(f\"Skipping {id}\")\n",
        "                continue\n",
        "\n",
        "            duration_file_path = os.path.join(durations_folder, f\"{id}.npy\")\n",
        "            np.save(duration_file_path, duration)\n",
        "\n",
        "\n",
        "            json_dict[id].update({\"label_phoneme\": label_phoneme})\n",
        "            json_dict[id].update({\"spn_labels\": spn_labels})\n",
        "            json_dict[id].update({\"start\": start})\n",
        "            json_dict[id].update({\"end\": end})\n",
        "            json_dict[id].update({\"durations\": duration_file_path})\n",
        "            json_dict[id].update(\n",
        "                {\"last_phoneme_flags\": trimmed_last_phoneme_flags}\n",
        "            )\n",
        "\n",
        "    with open(json_file, mode=\"w\") as json_f:\n",
        "        json.dump(json_dict, json_f, indent=2)\n",
        "\n",
        "    logger.info(f\"{json_file} successfully created!\")\n",
        "\n",
        "\n",
        "def get_alignment(tier, sampling_rate, hop_length, last_phoneme_flags):\n",
        "\n",
        "    sil_phones = [\"sil\", \"sp\", \"spn\", \"\"]\n",
        "\n",
        "    phonemes = []\n",
        "    durations = []\n",
        "    start_time = 0\n",
        "    end_time = 0\n",
        "    end_idx = 0\n",
        "    trimmed_last_phoneme_flags = []\n",
        "\n",
        "    flag_iter = iter(last_phoneme_flags)\n",
        "\n",
        "    for t in tier._objects:\n",
        "        s, e, p = t.start_time, t.end_time, t.text\n",
        "        current_flag = next(flag_iter)\n",
        "        if phonemes == []:\n",
        "            if p in sil_phones:\n",
        "                continue\n",
        "            else:\n",
        "                start_time = s\n",
        "\n",
        "        if p not in sil_phones:\n",
        "            if p[-1].isdigit():\n",
        "                phonemes.append(p[:-1])\n",
        "            else:\n",
        "                phonemes.append(p)\n",
        "            trimmed_last_phoneme_flags.append(current_flag[1])\n",
        "            end_time = e\n",
        "            end_idx = len(phonemes)\n",
        "        else:\n",
        "            phonemes.append(\"spn\")\n",
        "            trimmed_last_phoneme_flags.append(current_flag[1])\n",
        "\n",
        "        durations.append(\n",
        "            int(\n",
        "                np.round(e * sampling_rate / hop_length)\n",
        "                - np.round(s * sampling_rate / hop_length)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    phonemes = phonemes[:end_idx]\n",
        "    durations = durations[:end_idx]\n",
        "\n",
        "    return phonemes, durations, start_time, end_time, trimmed_last_phoneme_flags\n",
        "\n",
        "\n",
        "def get_last_phoneme_info(words_seq, phones_seq):\n",
        "\n",
        "    phoneme_objects = phones_seq._objects\n",
        "    phoneme_iter = iter(phoneme_objects)\n",
        "\n",
        "    last_phoneme_flags = list()\n",
        "\n",
        "    for word_obj in words_seq._objects:\n",
        "        word_end_time = word_obj.end_time\n",
        "\n",
        "        current_phoneme = next(phoneme_iter, None)\n",
        "        while current_phoneme:\n",
        "            phoneme_end_time = current_phoneme.end_time\n",
        "            if phoneme_end_time == word_end_time:\n",
        "                last_phoneme_flags.append((current_phoneme.text, 1))\n",
        "                break\n",
        "            else:\n",
        "                last_phoneme_flags.append((current_phoneme.text, 0))\n",
        "            current_phoneme = next(phoneme_iter, None)\n",
        "\n",
        "    return last_phoneme_flags\n",
        "\n",
        "\n",
        "def custom_clean(text, model_name):\n",
        "\n",
        "    _abbreviations = [\n",
        "        (re.compile(\"\\\\b%s\\\\.\" % x[0], re.IGNORECASE), x[1])\n",
        "        for x in [\n",
        "            (\"mrs\", \"missus\"),\n",
        "            (\"mr\", \"mister\"),\n",
        "            (\"dr\", \"doctor\"),\n",
        "            (\"st\", \"saint\"),\n",
        "            (\"co\", \"company\"),\n",
        "            (\"jr\", \"junior\"),\n",
        "            (\"maj\", \"major\"),\n",
        "            (\"gen\", \"general\"),\n",
        "            (\"drs\", \"doctors\"),\n",
        "            (\"rev\", \"reverend\"),\n",
        "            (\"lt\", \"lieutenant\"),\n",
        "            (\"hon\", \"honorable\"),\n",
        "            (\"sgt\", \"sergeant\"),\n",
        "            (\"capt\", \"captain\"),\n",
        "            (\"esq\", \"esquire\"),\n",
        "            (\"ltd\", \"limited\"),\n",
        "            (\"col\", \"colonel\"),\n",
        "            (\"ft\", \"fort\"),\n",
        "        ]\n",
        "    ]\n",
        "    text = unidecode(text.lower())\n",
        "    if model_name != \"FastSpeech2WithAlignment\":\n",
        "        text = re.sub(\"[:;]\", \" - \", text)\n",
        "        text = re.sub(r'[)(\\[\\]\"]', \" \", text)\n",
        "        text = text.strip().strip().strip(\"-\")\n",
        "\n",
        "    text = re.sub(\" +\", \" \", text)\n",
        "    for regex, replacement in _abbreviations:\n",
        "        text = re.sub(regex, replacement, text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trigger the above code block to prepare Train and Valid split for LJSPEECH dataset at 90 and 10"
      ],
      "metadata": {
        "id": "cd5549kUuAGf"
      },
      "id": "cd5549kUuAGf"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "00e76ec9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "8eea731c792b44289d88139abf99856d",
            "37fef45307f348c0baba4436d8caf288",
            "5b3db8a91ec245b3910547e63a262363",
            "880d89cb142b4018a3ce6090c0836c77",
            "6f8a2703ef80484d81f0b2a33e5a26b8",
            "a0fd2fbef4224e97987122e4ecee9061",
            "eab08aca599b42b7a80eb614893bad28",
            "88ad9961864943e4a6b71189d5610a3c",
            "3bb90181c5884402ae74ce1c806e654f",
            "ed574c637f1a4d969afdc7d4a6e03aef",
            "ee3ef5bb3015474b921a8ac7658538c1",
            "e2b7694d43f14b0bb0cfb13267099003",
            "6cd23a012a4f46dbb3a81fae3794fd18",
            "52af0aaacec8454789afebd0eba9ab99",
            "5d380d695e3343f7b5f937adbc5efa49",
            "bb1372b1f61344bbb14221791eecdf26",
            "d082baee57a74ee6bfae441aa8270cca",
            "ed12c3392abc4ff0abdd28eedfbf1a74",
            "3f02f630405740f885668263a05e2f50",
            "ad44ba91795d40e498ccc8200e5464cd",
            "424b6e22f9b445cb91679c74d85fdf5b",
            "26628264149341788b59e90dc86db726",
            "7372719780404a2a84809a0a37db7e9d",
            "48eaf4b78c96419a8a85ac5a8841ead4",
            "06f38e64742a48f99c7bd1497e067e4c",
            "61c65f8590664b388fd1ed13ef61f488",
            "6666efb651cb4283aa5d5635c1d49334",
            "75b24732d0794a3692e224c2592747c9",
            "78319c6771ec4a3c930df7e3a813a72d",
            "36e07edc60394830bb3d936fa9de2704",
            "be09730a704f44eba1131670a03c42a6",
            "9083058889cb4ca6ad2cec05f4213626",
            "56ef28a46a184bb19c0b4b0c04503bbf",
            "54a23b5f818b4498a18a9fe59fedcc6f",
            "45708e95ab1e42ab852aeb8ec5fb42b7",
            "7bd454536a114446937311d9befaf020",
            "4938ce874ba24893b3aa4955ff8ac111",
            "ac86644e6923417bbd570c2b1ed35fa6",
            "73ac4ba4fc784b549e5073a452624ab2",
            "75e4d74346a34460a9a6c8e6fd25b713",
            "b7d8e9b56d494312bd440341ea0a4b05",
            "2d8e6e13d732408a9c1a006201f7c8d8",
            "a6ac6771c51c4c7d9a49c8c6a468c774",
            "4b735ce6a5ca404699cae415e6ff923f",
            "5e6c899da7034b56a982da7787f1edeb",
            "ba978c7319bf44d8967b58e2b3c255d1",
            "3b6f3ccb9ccd4bc9b83458842bc15b65",
            "22ebec9e4711433ea8cee13031339633",
            "623e0768b5bc4346abeff0f7699dacdb",
            "c556f9e74d124c14826778d4fa90d979",
            "c0cc3fcd40944fef8da047c7cec0f5a4",
            "96d0c66f1f3a4ebeb122304f6e53fc78",
            "3471f27bc5774c98a25c4b8d3eead176",
            "e701627f721a4756b567f144bc6aa93f",
            "3886ccc4af464a8087f581da8a8b1efa",
            "710c51edb33a48649d5d4dc95d093280",
            "75e2e2cbfc9d4397980c536c53a1f9c3",
            "acf390c4ddd741bd98a4dc1466eecb04",
            "4c165c25e4234966ba508baa7eb9d737",
            "14b29ecfe2034a8a9c36235ecb87eb69",
            "c19277b152ae45a9b5dd01ce6ff90fa7",
            "0b5d2cda6a1b499c807c1f46e35bf0eb",
            "6450e72a35cb4bf8b415fb2c6c48e93b",
            "734372c1d3874a1ca6b18267b4eb1d9a",
            "d9ae94a2687944e493b5d30e6f47d934",
            "2e05bfe6b97d4df99f200e9eb647bb15",
            "0855f061a75f4e75a420285277da293a",
            "a8c7d857db1e4335af1db4c1a5e09c98",
            "aa8c130dbd7145068ca0aa2fc2c548e4",
            "eafe835f5127474bb8b5c1f99b2f5e03",
            "a0f08e92309c4f15ae0836efdcd6bee7",
            "b72cef7b7c3a414e8374bec36a5ddd82",
            "e45d74cac99344fcbb96d2541881db36",
            "804b885f2b0b48bda134b029804145d8",
            "ae79700edf90484382ea3c4f053bfc40",
            "1a03afcb5961428bb6bab96a06b5c890",
            "622df8151d8e4fc7afe758813cfb5e53",
            "871cd0d5855d4173934f11505692f77f",
            "be5229b11b92408595e3a184a2689c21",
            "03e8d58719f4464e9864c6ee22942e24",
            "bb322f0a51664a238d92db22d36efb9f",
            "65b4aa1ceb7043438e5432e335f485ef",
            "149be4952a294c01b41604c177fea35a",
            "86b078fa896148a09832940f4102601f",
            "d8122674de4a4f92a254beb29c76425a",
            "d0ddd4a70cc2422ca9edc860d670dd0d",
            "a4254f0e74b141c7a0d91f3b7e5889fb",
            "b4770617dc3b47eeb20925cba974bcef"
          ]
        },
        "id": "00e76ec9",
        "outputId": "a4405b59-e0a1-4622-f3ff-3e3ddf9206bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.dropbox.com/s/v28x5ldqqa288pu/LJSpeech.zip?dl=1 to data/LJSpeech-1.1/alignments.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LJSpeech.zip?dl=1: 18.1MB [00:01, 14.9MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/LJSpeech-1.1/alignments.zip to data/LJSpeech-1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "hyperparams.yaml:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eea731c792b44289d88139abf99856d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.ckpt:   0%|          | 0.00/129M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2b7694d43f14b0bb0cfb13267099003"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ctc_lin.ckpt:   0%|          | 0.00/177k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7372719780404a2a84809a0a37db7e9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54a23b5f818b4498a18a9fe59fedcc6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e6c899da7034b56a982da7787f1edeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "710c51edb33a48649d5d4dc95d093280"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0855f061a75f4e75a420285277da293a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "871cd0d5855d4173934f11505692f77f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167/167 [00:03<00:00, 49.60it/s]\n",
            "100%|██████████| 19/19 [00:00<00:00, 76.15it/s]\n"
          ]
        }
      ],
      "source": [
        "prepare_ljspeech( save_folder = r'results/save', data_folder= r'data/LJSpeech-1.1', splits=[\"train\", \"valid\"], model_name = 'FastSpeech2', split_ratio=[90, 10], seed=1234, skip_prep=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TransformersTTS.py\n",
        "\n",
        "The `TransformersTTS.py` script implements a Transformer-based Text-to-Speech (TTS) model using PyTorch. The model consists of an encoder and a decoder, each composed of several components.\n",
        "\n",
        "1. **Encoder**:\n",
        "   - The encoder takes input characters (text) and converts them into a sequence of embeddings.\n",
        "   - These embeddings are then augmented with positional encodings and processed through multiple layers of self-attention mechanisms and feed-forward neural networks.\n",
        "   - The encoder outputs a contextual representation of the input text, which captures its semantic information.\n",
        "\n",
        "2. **Decoder**:\n",
        "   - The decoder takes the mel-spectrogram features (acoustic features) as input along with the positional encodings.\n",
        "   - Similar to the encoder, the decoder also employs self-attention mechanisms and feed-forward neural networks.\n",
        "   - The decoder generates mel-spectrogram predictions step by step, conditioned on the input text representation produced by the encoder.\n",
        "   - Additionally, the decoder predicts stop tokens to indicate the end of the mel-spectrogram sequence generation.\n",
        "\n",
        "3. **Additional Components**:\n",
        "   - The code includes modules for linear transformations, convolutions, multi-head attention mechanisms, and positional embeddings.\n",
        "   - These components are essential for building the layers of the Transformer architecture and ensuring proper information flow between encoder and decoder.\n",
        "\n",
        "4. **Model Class**:\n",
        "   - The `Model` class encapsulates the entire Transformer TTS architecture by combining the encoder and decoder modules.\n",
        "   - During forward pass, it takes input characters and mel-spectrogram features, processes them through the encoder and decoder respectively, and returns the predicted mel-spectrogram output along with attention probabilities and stop predictions.\n",
        "\n",
        "The implementation of **Transformer TTS** owes much to the work of **Soobinseo** [7], whose GitHub repository served as a valuable reference. While our approach differs significantly in some aspects—for instance, we utilize phonemes instead of characters and opt for HIFIGan over WaveNet due to its superior performance and generalizability—the foundation laid by Soobinseo's work remains pivotal to our project."
      ],
      "metadata": {
        "id": "sdl6ViAsyocu"
      },
      "id": "sdl6ViAsyocu"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e0fd3f41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0fd3f41",
        "outputId": "b136a1e7-c19e-4458-d1e3-ef994bb7a00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing TransformersTTS.py\n"
          ]
        }
      ],
      "source": [
        "%%file TransformersTTS.py\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch as t\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "import copy\n",
        "from collections import OrderedDict\n",
        "from speechbrain.lobes.models.transformer.Transformer import PositionalEncoding\n",
        "\n",
        "\n",
        "def get_sinusoid_encoding_table(seq_len, hidden_dim, padding_idx=None):\n",
        "    position = t.arange(0, seq_len, dtype=t.float).unsqueeze(1)\n",
        "    div_term = t.exp(t.arange(0, hidden_dim, 2).float() * (-t.log(t.tensor(10000.0)) / hidden_dim))\n",
        "    sinusoid_inp = t.arange(0, hidden_dim, 2).float() / hidden_dim\n",
        "    sinusoid_inp = t.sin(sinusoid_inp * t.tensor([math.pi]))\n",
        "    position_encoding = t.zeros(seq_len, hidden_dim)\n",
        "    position_encoding[:, 0::2] = t.sin(position * div_term)\n",
        "    position_encoding[:, 1::2] = t.cos(position * div_term)\n",
        "    if padding_idx is not None:\n",
        "        position_encoding[padding_idx] = 0.\n",
        "    return position_encoding\n",
        "\n",
        "\n",
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "class Linear(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear Module\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, out_dim, bias=True, w_init='linear'):\n",
        "        \"\"\"\n",
        "        :param in_dim: dimension of input\n",
        "        :param out_dim: dimension of output\n",
        "        :param bias: boolean. if True, bias is included.\n",
        "        :param w_init: str. weight inits with xavier initialization.\n",
        "        \"\"\"\n",
        "        super(Linear, self).__init__()\n",
        "        self.linear_layer = nn.Linear(in_dim, out_dim, bias=bias)\n",
        "\n",
        "        nn.init.xavier_uniform_(\n",
        "            self.linear_layer.weight,\n",
        "            gain=nn.init.calculate_gain(w_init))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution Module\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1,\n",
        "                 padding=0, dilation=1, bias=True, w_init='linear'):\n",
        "        \"\"\"\n",
        "        :param in_channels: dimension of input\n",
        "        :param out_channels: dimension of output\n",
        "        :param kernel_size: size of kernel\n",
        "        :param stride: size of stride\n",
        "        :param padding: size of padding\n",
        "        :param dilation: dilation rate\n",
        "        :param bias: boolean. if True, bias is included.\n",
        "        :param w_init: str. weight inits with xavier initialization.\n",
        "        \"\"\"\n",
        "        super(Conv, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels,\n",
        "                              kernel_size=kernel_size, stride=stride,\n",
        "                              padding=padding, dilation=dilation,\n",
        "                              bias=bias)\n",
        "\n",
        "        nn.init.xavier_uniform_(\n",
        "            self.conv.weight, gain=nn.init.calculate_gain(w_init))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class PostConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Post Convolutional Network (mel --> mel)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_hidden):\n",
        "        \"\"\"\n",
        "\n",
        "        :param num_hidden: dimension of hidden\n",
        "        \"\"\"\n",
        "        self.num_mels = 80\n",
        "        self.outputs_per_step = 1\n",
        "\n",
        "        super(PostConvNet, self).__init__()\n",
        "        self.conv1 = Conv(in_channels=self.num_mels * self.outputs_per_step,\n",
        "                          out_channels=num_hidden,\n",
        "                          kernel_size=5,\n",
        "                          padding=4,\n",
        "                          w_init='tanh')\n",
        "        self.conv_list = clones(Conv(in_channels=num_hidden,\n",
        "                                     out_channels=num_hidden,\n",
        "                                     kernel_size=5,\n",
        "                                     padding=4,\n",
        "                                     w_init='tanh'), 3)\n",
        "        self.conv2 = Conv(in_channels=num_hidden,\n",
        "                          out_channels=self.num_mels * self.outputs_per_step,\n",
        "                          kernel_size=5,\n",
        "                          padding=4)\n",
        "\n",
        "        self.batch_norm_list = clones(nn.BatchNorm1d(num_hidden), 3)\n",
        "        self.pre_batchnorm = nn.BatchNorm1d(num_hidden)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        self.dropout_list = nn.ModuleList([nn.Dropout(p=0.1) for _ in range(3)])\n",
        "\n",
        "    def forward(self, input_, mask=None):\n",
        "        input_ = self.dropout1(t.tanh(self.pre_batchnorm(self.conv1(input_)[:, :, :-4])))\n",
        "        for batch_norm, conv, dropout in zip(self.batch_norm_list, self.conv_list, self.dropout_list):\n",
        "            input_ = dropout(t.tanh(batch_norm(conv(input_)[:, :, :-4])))\n",
        "        input_ = self.conv2(input_)[:, :, :-4]\n",
        "        return input_\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    \"\"\"\n",
        "    Positionwise Feed-Forward Network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_hidden):\n",
        "        \"\"\"\n",
        "        :param num_hidden: dimension of hidden\n",
        "        \"\"\"\n",
        "        super(FFN, self).__init__()\n",
        "        self.w_1 = Conv(num_hidden, num_hidden * 4, kernel_size=1, w_init='relu')\n",
        "        self.w_2 = Conv(num_hidden * 4, num_hidden, kernel_size=1)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.layer_norm = nn.LayerNorm(num_hidden)\n",
        "\n",
        "    def forward(self, input_):\n",
        "        x = input_.transpose(1, 2)\n",
        "        x = self.w_2(t.relu(self.w_1(x)))\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        x = x + input_\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention Network\n",
        "    \"\"\"\n",
        "    def __init__(self, num_hidden, h=4):\n",
        "        \"\"\"\n",
        "        :param num_hidden: dimension of hidden\n",
        "        :param h: num of heads\n",
        "        \"\"\"\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_hidden_per_attn = num_hidden // h\n",
        "        self.h = h\n",
        "\n",
        "        self.key = Linear(num_hidden, num_hidden, bias=False)\n",
        "        self.value = Linear(num_hidden, num_hidden, bias=False)\n",
        "        self.query = Linear(num_hidden, num_hidden, bias=False)\n",
        "\n",
        "        self.multihead = MultiheadAttention(self.num_hidden_per_attn)\n",
        "\n",
        "        self.residual_dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        self.final_linear = Linear(num_hidden * 2, num_hidden)\n",
        "\n",
        "        self.layer_norm_1 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "    def forward(self, memory, decoder_input, mask=None, query_mask=None):\n",
        "\n",
        "        batch_size = memory.size(0)\n",
        "        seq_k = memory.size(1)\n",
        "        seq_q = decoder_input.size(1)\n",
        "\n",
        "        if query_mask is not None:\n",
        "            query_mask = query_mask.unsqueeze(-1).repeat(1, 1, seq_k)\n",
        "            query_mask = query_mask.repeat(self.h, 1, 1)\n",
        "        if mask is not None:\n",
        "            mask = mask.repeat(self.h, 1, 1)\n",
        "\n",
        "        key = self.key(memory).view(batch_size, seq_k, self.h, self.num_hidden_per_attn)\n",
        "        value = self.value(memory).view(batch_size, seq_k, self.h, self.num_hidden_per_attn)\n",
        "        query = self.query(decoder_input).view(batch_size, seq_q, self.h, self.num_hidden_per_attn)\n",
        "\n",
        "        key = key.permute(2, 0, 1, 3).contiguous().view(-1, seq_k, self.num_hidden_per_attn)\n",
        "        value = value.permute(2, 0, 1, 3).contiguous().view(-1, seq_k, self.num_hidden_per_attn)\n",
        "        query = query.permute(2, 0, 1, 3).contiguous().view(-1, seq_q, self.num_hidden_per_attn)\n",
        "\n",
        "        result, attns = self.multihead(key, value, query, mask=mask, query_mask=query_mask)\n",
        "\n",
        "        result = result.view(self.h, batch_size, seq_q, self.num_hidden_per_attn)\n",
        "        result = result.permute(1, 2, 0, 3).contiguous().view(batch_size, seq_q, -1)\n",
        "\n",
        "        result = t.cat([decoder_input, result], dim=-1)\n",
        "\n",
        "        result = self.final_linear(result)\n",
        "\n",
        "        result = result + decoder_input\n",
        "\n",
        "        result = self.layer_norm_1(result)\n",
        "\n",
        "        return result, attns\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multihead attention mechanism (dot attention)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_hidden_k):\n",
        "        \"\"\"\n",
        "        :param num_hidden_k: dimension of hidden\n",
        "        \"\"\"\n",
        "        super(MultiheadAttention, self).__init__()\n",
        "\n",
        "        self.num_hidden_k = num_hidden_k\n",
        "        self.attn_dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    def forward(self, key, value, query, mask=None, query_mask=None):\n",
        "\n",
        "        attn = t.bmm(query, key.transpose(1, 2))\n",
        "        attn = attn / math.sqrt(self.num_hidden_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask, -2 ** 32 + 1)\n",
        "            attn = t.softmax(attn, dim=-1)\n",
        "        else:\n",
        "            attn = t.softmax(attn, dim=-1)\n",
        "\n",
        "        if query_mask is not None:\n",
        "            attn = attn * query_mask\n",
        "\n",
        "        result = t.bmm(attn, value)\n",
        "\n",
        "        return result, attn\n",
        "\n",
        "\n",
        "\n",
        "class Prenet(nn.Module):\n",
        "    \"\"\"\n",
        "    Prenet before passing through the network\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, p=0.5):\n",
        "        \"\"\"\n",
        "        :param input_size: dimension of input\n",
        "        :param hidden_size: dimension of hidden unit\n",
        "        :param output_size: dimension of output\n",
        "        \"\"\"\n",
        "        super(Prenet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.layer = nn.Sequential(OrderedDict([\n",
        "             ('fc1', Linear(self.input_size, self.hidden_size)),\n",
        "             ('relu1', nn.ReLU()),\n",
        "             ('dropout1', nn.Dropout(p)),\n",
        "             ('fc2', Linear(self.hidden_size, self.output_size)),\n",
        "             ('relu2', nn.ReLU()),\n",
        "             ('dropout2', nn.Dropout(p)),\n",
        "        ]))\n",
        "\n",
        "    def forward(self, input_):\n",
        "\n",
        "        out = self.layer(input_)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class EncoderPrenet(nn.Module):\n",
        "    \"\"\"\n",
        "    Pre-network for Encoder consists of convolution networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_size, num_hidden):\n",
        "        super(EncoderPrenet, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embed = nn.Embedding(42, embedding_size, padding_idx=0)\n",
        "\n",
        "        self.conv1 = Conv(in_channels=embedding_size,\n",
        "                          out_channels=num_hidden,\n",
        "                          kernel_size=5,\n",
        "                          padding=int(np.floor(5 / 2)),\n",
        "                          w_init='relu')\n",
        "        self.conv2 = Conv(in_channels=num_hidden,\n",
        "                          out_channels=num_hidden,\n",
        "                          kernel_size=5,\n",
        "                          padding=int(np.floor(5 / 2)),\n",
        "                          w_init='relu')\n",
        "\n",
        "        self.conv3 = Conv(in_channels=num_hidden,\n",
        "                          out_channels=num_hidden,\n",
        "                          kernel_size=5,\n",
        "                          padding=int(np.floor(5 / 2)),\n",
        "                          w_init='relu')\n",
        "\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_hidden)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(num_hidden)\n",
        "        self.batch_norm3 = nn.BatchNorm1d(num_hidden)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.2)\n",
        "        self.dropout2 = nn.Dropout(p=0.2)\n",
        "        self.dropout3 = nn.Dropout(p=0.2)\n",
        "        self.projection = Linear(num_hidden, num_hidden)\n",
        "\n",
        "    def forward(self, input_):\n",
        "        input_ = self.embed(input_)\n",
        "        input_ = input_.transpose(1, 2)\n",
        "        input_ = self.dropout1(t.relu(self.batch_norm1(self.conv1(input_))))\n",
        "        input_ = self.dropout2(t.relu(self.batch_norm2(self.conv2(input_))))\n",
        "        input_ = self.dropout3(t.relu(self.batch_norm3(self.conv3(input_))))\n",
        "        input_ = input_.transpose(1, 2)\n",
        "        input_ = self.projection(input_)\n",
        "\n",
        "        return input_\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder Network\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_size, num_hidden):\n",
        "        \"\"\"\n",
        "        :param embedding_size: dimension of embedding\n",
        "        :param num_hidden: dimension of hidden\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_d_model = 384\n",
        "        self.alpha = nn.Parameter(t.ones(1))\n",
        "        self.num_hidden = num_hidden\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(1024, num_hidden, padding_idx=0),\n",
        "                                                    freeze=True)\n",
        "        self.pos_dropout = nn.Dropout(p=0.1)\n",
        "        self.encoder_prenet = EncoderPrenet(embedding_size, num_hidden)\n",
        "        self.layers = clones(Attention(num_hidden), 3)\n",
        "        self.ffns = clones(FFN(num_hidden), 3)\n",
        "\n",
        "\n",
        "    def forward(self, x, pos):\n",
        "\n",
        "        if self.training:\n",
        "            c_mask = pos.ne(0).type(t.float)\n",
        "            mask = pos.eq(0).unsqueeze(1).repeat(1, x.size(1), 1)\n",
        "\n",
        "        else:\n",
        "            c_mask, mask = None, None\n",
        "\n",
        "        x = self.encoder_prenet(x)\n",
        "\n",
        "\n",
        "        pos = self.pos_emb(pos)\n",
        "\n",
        "        x = pos * self.alpha + x\n",
        "\n",
        "        x = self.pos_dropout(x)\n",
        "\n",
        "        attns = list()\n",
        "        for layer, ffn in zip(self.layers, self.ffns):\n",
        "            x, attn = layer(x, x, mask=mask, query_mask=c_mask)\n",
        "            x = ffn(x)\n",
        "            attns.append(attn)\n",
        "\n",
        "        return x, c_mask, attns\n",
        "\n",
        "\n",
        "class MelDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder Network\n",
        "    \"\"\"\n",
        "    def __init__(self, num_hidden):\n",
        "        \"\"\"\n",
        "        :param num_hidden: dimension of hidden\n",
        "        \"\"\"\n",
        "        self.num_mels = 80\n",
        "        self.outputs_per_step = 1\n",
        "        super(MelDecoder, self).__init__()\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(1024, num_hidden, padding_idx=0),\n",
        "                                                    freeze=True)\n",
        "        self.pos_dropout = nn.Dropout(p=0.1)\n",
        "        self.alpha = nn.Parameter(t.ones(1))\n",
        "        self.decoder_prenet = Prenet(self.num_mels, num_hidden * 2, num_hidden, p=0.2)\n",
        "        self.norm = Linear(num_hidden, num_hidden)\n",
        "\n",
        "        self.selfattn_layers = clones(Attention(num_hidden), 3)\n",
        "        self.dotattn_layers = clones(Attention(num_hidden), 3)\n",
        "        self.ffns = clones(FFN(num_hidden), 3)\n",
        "        self.mel_linear = Linear(num_hidden, self.num_mels * self.outputs_per_step)\n",
        "        self.stop_linear = Linear(num_hidden, 1, w_init='sigmoid')   #80\n",
        "\n",
        "        self.postconvnet = PostConvNet(num_hidden)\n",
        "\n",
        "    def forward(self, memory, decoder_input, c_mask, pos):\n",
        "        batch_size = memory.size(0)\n",
        "        decoder_len = decoder_input.size(1)\n",
        "\n",
        "        if self.training:\n",
        "            m_mask = pos.ne(0).type(t.float)\n",
        "            mask = m_mask.eq(0).unsqueeze(1).repeat(1, decoder_len, 1)\n",
        "            if next(self.parameters()).is_cuda:\n",
        "                mask = mask + t.triu(t.ones(decoder_len, decoder_len).cuda(), diagonal=1).repeat(batch_size, 1, 1).byte()\n",
        "            else:\n",
        "                mask = mask + t.triu(t.ones(decoder_len, decoder_len), diagonal=1).repeat(batch_size, 1, 1).byte()\n",
        "            mask = mask.gt(0)\n",
        "            zero_mask = c_mask.eq(0).unsqueeze(-1).repeat(1, 1, decoder_len)\n",
        "            zero_mask = zero_mask.transpose(1, 2)\n",
        "        else:\n",
        "            if next(self.parameters()).is_cuda:\n",
        "                mask = t.triu(t.ones(decoder_len, decoder_len).cuda(), diagonal=1).repeat(batch_size, 1, 1).byte()\n",
        "            else:\n",
        "                mask = t.triu(t.ones(decoder_len, decoder_len), diagonal=1).repeat(batch_size, 1, 1).byte()\n",
        "            mask = mask.gt(0)\n",
        "            m_mask, zero_mask = None, None\n",
        "\n",
        "        decoder_input = self.decoder_prenet(decoder_input)\n",
        "\n",
        "        decoder_input = self.norm(decoder_input)\n",
        "\n",
        "        pos = self.pos_emb(pos)\n",
        "        decoder_input = pos * self.alpha + decoder_input\n",
        "\n",
        "        decoder_input = self.pos_dropout(decoder_input)\n",
        "\n",
        "        attn_dot_list = list()\n",
        "        attn_dec_list = list()\n",
        "\n",
        "        for selfattn, dotattn, ffn in zip(self.selfattn_layers, self.dotattn_layers, self.ffns):\n",
        "            decoder_input, attn_dec = selfattn(decoder_input, decoder_input, mask=mask, query_mask=m_mask)\n",
        "            decoder_input, attn_dot = dotattn(memory, decoder_input, mask=zero_mask, query_mask=m_mask)\n",
        "            decoder_input = ffn(decoder_input)\n",
        "            attn_dot_list.append(attn_dot)\n",
        "            attn_dec_list.append(attn_dec)\n",
        "\n",
        "        mel_out = self.mel_linear(decoder_input)\n",
        "\n",
        "        postnet_input = mel_out.transpose(1, 2)\n",
        "        out = self.postconvnet(postnet_input)\n",
        "        out = postnet_input + out\n",
        "        out = out.transpose(1, 2)\n",
        "\n",
        "        stop_tokens = self.stop_linear(decoder_input)\n",
        "\n",
        "        return mel_out, out, attn_dot_list, stop_tokens, attn_dec_list\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "\n",
        "        self.embedding_size = 512\n",
        "        self.hidden_size = 256\n",
        "        super(Model, self).__init__()\n",
        "        self.encoder = Encoder(self.embedding_size, self.hidden_size)\n",
        "        self.decoder = MelDecoder(self.hidden_size)\n",
        "\n",
        "    def forward(self, characters, mel_input, pos_text, pos_mel):\n",
        "        mel_input = mel_input.permute(0, 2, 1)\n",
        "        memory, c_mask, attns_enc = self.encoder.forward(characters, pos=pos_text)\n",
        "\n",
        "        mel_output, postnet_output, attn_probs, stop_preds, attns_dec = self.decoder.forward(memory, mel_input, c_mask,\n",
        "                                                                                             pos=pos_mel)\n",
        "\n",
        "        return mel_output, postnet_output, attn_probs, stop_preds, attns_enc, attns_dec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The utils file defines a custom loss function class called Loss for training the FastSpeech2 model used in speech synthesis but we use it for our TTs Transformer and make it compatible with model and phonemes data.\n",
        "\n",
        "It computes various loss components, including mel-spectrogram loss, postnet mel-spectrogram loss, SSIM loss, and gate loss, and combines them to calculate the total loss during training. These losses are weighted and aggregated to guide the model training process effectively.\n",
        "\n",
        "I tried using non-gated version loss as well but it was not giving optimal results on stop token but indeed enhanced the quality rapidly."
      ],
      "metadata": {
        "id": "m2Ccj-oM2HZD"
      },
      "id": "m2Ccj-oM2HZD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It also houses a class called TextMelAlignmentCollator. It's designed to help organize batches of data during training or testing of a speech synthesis model.\n",
        "\n",
        "When you use this collate function, it sorts the batch of data based on the lengths of phoneme sequences and mel spectrograms. Then, it pads the sequences with zeros to make sure they all have the same length.\n",
        "\n",
        "After organizing the data, it returns everything in a structured way, including the padded sequences, input and output lengths, gate values, and additional information like waveforms and labels."
      ],
      "metadata": {
        "id": "iMDPls00yNAu"
      },
      "id": "iMDPls00yNAu"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Ngk2KTk2pMss",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngk2KTk2pMss",
        "outputId": "3c50360b-c86c-4124-fa76-cc9e4672e44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ],
      "source": [
        "%%file utils.py\n",
        "\n",
        "import torch\n",
        "from speechbrain.nnet.losses import bce_loss\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from speechbrain.lobes.models.FastSpeech2 import SSIMLoss\n",
        "import numpy as np\n",
        "\n",
        "class Loss(torch.nn.Module):\n",
        "    def __init__(self, ssim_loss_weight, mel_loss_weight, postnet_mel_loss_weight, gate_loss_weight=1.0, gate_loss_max_epochs=8):\n",
        "        super().__init__()\n",
        "        self.l1_loss = torch.nn.L1Loss()\n",
        "        self.ssim_loss = SSIMLoss()\n",
        "        self.mse_loss = torch.nn.MSELoss()\n",
        "        self.ssim_loss_weight = ssim_loss_weight\n",
        "        self.mel_loss_weight = mel_loss_weight\n",
        "        self.postnet_mel_loss_weight = postnet_mel_loss_weight\n",
        "        self.gate_loss_weight = gate_loss_weight\n",
        "        self.gate_loss_max_epochs = gate_loss_max_epochs\n",
        "\n",
        "    def forward(self, mel_pred, mel, postnet_pred, gate_target, stop_preds, mel_lengths, mask, current_epoch):\n",
        "        mel_losses = []\n",
        "        postnet_mel_losses = []\n",
        "\n",
        "        for i in range(mel.shape[0]):\n",
        "            mel_loss = self.mse_loss(mel_pred[i, :mel_lengths[i], :], mel[i, :mel_lengths[i], :])\n",
        "            postnet_mel_loss = self.mse_loss(postnet_pred[i, :mel_lengths[i], :], mel[i, :mel_lengths[i], :])\n",
        "            mel_losses.append(mel_loss)\n",
        "            postnet_mel_losses.append(postnet_mel_loss)\n",
        "\n",
        "        ssim_loss = self.ssim_loss(mel_pred, mel, mel_lengths)\n",
        "        mel_loss = sum(mel_losses) / len(mel)\n",
        "        postnet_mel_loss = sum(postnet_mel_losses) / len(mel)\n",
        "\n",
        "        gate_target_masked = gate_target.masked_select(mask)\n",
        "        stop_preds_masked = stop_preds.squeeze(-1).masked_select(mask)\n",
        "\n",
        "        gate_loss = bce_loss(stop_preds_masked, gate_target_masked, pos_weight=torch.tensor(5.0))\n",
        "\n",
        "        total_loss = (ssim_loss * self.ssim_loss_weight) + (mel_loss * self.mel_loss_weight) + (postnet_mel_loss * self.postnet_mel_loss_weight) + (gate_loss * self.gate_loss_weight)\n",
        "\n",
        "        loss_dict = {\n",
        "            \"total_loss\": total_loss,\n",
        "            \"ssim_loss\": ssim_loss * self.ssim_loss_weight,\n",
        "            \"mel_loss\": mel_loss * self.mel_loss_weight,\n",
        "            \"postnet_mel_loss\": postnet_mel_loss * self.postnet_mel_loss_weight,\n",
        "            \"gate_loss\": gate_loss * self.gate_loss_weight,\n",
        "        }\n",
        "\n",
        "        return loss_dict\n",
        "\n",
        "class TextMelAlignmentCollator:\n",
        "    def __call__(self, batch_data):\n",
        "        raw_batch = list(batch_data)\n",
        "        for i, item in enumerate(batch_data):\n",
        "            batch_data[i] = item[\"mel_text_pair\"]\n",
        "\n",
        "        text_lengths, sorted_text_indices = torch.sort(\n",
        "            torch.LongTensor([len(x[0]) for x in batch_data]), dim=0, descending=True\n",
        "        )\n",
        "        mel_lengths, sorted_mel_indices = torch.sort(\n",
        "            torch.LongTensor([x[1].size(1) for x in batch_data]), dim=0, descending=True\n",
        "        )\n",
        "        max_mel_len = mel_lengths[0]\n",
        "        max_text_len = text_lengths[0]\n",
        "\n",
        "        padded_text = torch.LongTensor(len(batch_data), max_text_len).zero_()\n",
        "        for i, idx in enumerate(sorted_text_indices):\n",
        "            text = batch_data[idx][0]\n",
        "            padded_text[i, :text.size(0)] = text\n",
        "\n",
        "        padded_mel_pos = torch.LongTensor(len(batch_data), max_mel_len).zero_()\n",
        "        for i, idx in enumerate(sorted_mel_indices):\n",
        "            mel_pos = batch_data[idx][4]\n",
        "            padded_mel_pos[i, :mel_pos.size] = torch.LongTensor(mel_pos)\n",
        "\n",
        "        padded_text_pos = torch.LongTensor(len(batch_data), max_text_len).zero_()\n",
        "        for i, idx in enumerate(sorted_text_indices):\n",
        "            text_pos = batch_data[idx][3]\n",
        "            padded_text_pos[i, :text_pos.size] = torch.LongTensor(text_pos)\n",
        "\n",
        "        num_mels, max_target_len = batch_data[0][1].size(0), max(x[1].size(1) for x in batch_data)\n",
        "        padded_mels = torch.FloatTensor(len(batch_data), num_mels, max_target_len).zero_()\n",
        "        padded_mel_inputs = torch.FloatTensor(len(batch_data), num_mels, max_target_len).zero_()\n",
        "        padded_gates = torch.FloatTensor(len(batch_data), max_target_len).zero_()\n",
        "\n",
        "        output_lengths = torch.LongTensor(len(batch_data))\n",
        "        labels, wavs = [], []\n",
        "        for i, idx in enumerate(sorted_mel_indices):\n",
        "            mel = batch_data[idx][1]\n",
        "            mel_input = torch.tensor(batch_data[idx][2])\n",
        "            padded_mels[i, :, :mel.size(1)] = mel\n",
        "            padded_mel_inputs[i, :, :mel_input.size(1)] = mel_input\n",
        "            padded_gates[i, mel.size(1)-1:] = 1\n",
        "            output_lengths[i] = mel.size(1)\n",
        "            labels.append(raw_batch[idx][\"label\"])\n",
        "            wavs.append(raw_batch[idx][\"wav\"])\n",
        "\n",
        "        padded_mels = padded_mels.permute(0, 2, 1)\n",
        "        return (\n",
        "            padded_text,\n",
        "            padded_mels,\n",
        "            padded_mel_inputs,\n",
        "            padded_text_pos,\n",
        "            padded_mel_pos,\n",
        "            text_lengths,\n",
        "            output_lengths,\n",
        "            padded_gates,\n",
        "            wavs,\n",
        "            labels,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file, holds all the important settings and values needed to train a speech synthesis model. I've tried to stick to the instructions from the research paper as much as possible. The paper suggested training for 1000 epochs, but I stopped at around 920 epochs, which still gave good results.\n",
        "\n",
        "In this file, you'll find key parameters like the learning rate, how often the model saves its progress, and the number of examples it processes at once. These settings are crucial because they directly influence how well the model learns.\n",
        "\n",
        "To train the model, I used a powerful A4000 GPU for about 50 hours on Paperspace. This GPU is really fast and helped speed up the training process, making it possible to reach our training goals effectively.\n",
        "\n",
        "We started with less batch_size and interations to test initially on lower end GPU but increased the capacity on higher end GPU."
      ],
      "metadata": {
        "id": "yZAbVXnUuZQC"
      },
      "id": "yZAbVXnUuZQC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It also includes options for loading the data, keeping track of progress during training, and saving the trained model. Basically, it's a one-stop shop for setting up and running a TTS training session, giving you control over every aspect of the process. Most of the inspiration is taken from Fast speech hyper params and its model. we replace our model in place of the older one.\n",
        "\n",
        "After experimenting with various types of mel spectrograms, including custom ones, I found that the mel spectrogram provided by FastSpeech consistently outperformed the others. To ensure optimal performance, I carefully adjusted the hyperparameters to accommodate the dimensions of the Transformer model. This involved extensive experimentation to properly align the dimensions and fine-tune the parameters for the best results."
      ],
      "metadata": {
        "id": "H4BiaFcj77ng"
      },
      "id": "H4BiaFcj77ng"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "24e2f143",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24e2f143",
        "outputId": "c5f00fd9-46d3-48e7-d4e3-6cc97da2067b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hparams_tts.yaml\n"
          ]
        }
      ],
      "source": [
        "%%file hparams_tts.yaml\n",
        "\n",
        "seed: 1234\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "output_folder: !ref results\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "train_spn_predictor_epochs: 8\n",
        "progress_samples: True\n",
        "progress_sample_path: !ref <output_folder>/samples\n",
        "progress_samples_min_run: 10\n",
        "progress_samples_interval: 10\n",
        "progress_batch_sample_size: 4\n",
        "\n",
        "data_folder: #!PLACEHOLDER\n",
        "\n",
        "train_json: !ref <save_folder>/train.json\n",
        "valid_json: !ref <save_folder>/valid.json\n",
        "test_json: !ref <save_folder>/test.json\n",
        "\n",
        "splits: [\"train\", \"valid\"]\n",
        "split_ratio: [90, 10]\n",
        "\n",
        "skip_prep: False\n",
        "\n",
        "sample_rate: 22050\n",
        "hop_length: 256\n",
        "win_length: null\n",
        "n_mel_channels: 80\n",
        "mel_fmin: 0.0\n",
        "mel_fmax: 8000.0\n",
        "power: 1\n",
        "norm: \"slaney\"\n",
        "mel_scale: \"slaney\"\n",
        "dynamic_range_compression: True\n",
        "mel_normalized: False\n",
        "min_max_energy_norm: True\n",
        "min_f0: 65\n",
        "max_f0: 2093\n",
        "\n",
        "#Main HyperParams\n",
        "n_iter: 60\n",
        "outputs_per_step: 1\n",
        "epochs: 10000\n",
        "lr : 0.001\n",
        "save_step : 2000\n",
        "image_step : 500\n",
        "batch_size : 32\n",
        "\n",
        "num_mels : 80\n",
        "n_fft : 2048\n",
        "sr : 22050\n",
        "preemphasis : 0.97\n",
        "frame_shift : 0.0125\n",
        "frame_length : 0.05\n",
        "# hop_length : int(sr*frame_shift)\n",
        "# win_length : int(sr*frame_length)\n",
        "n_mels : 80\n",
        "# power : 1.2\n",
        "min_level_db : -100\n",
        "ref_level_db : 20\n",
        "hidden_size : 256\n",
        "embedding_size : 512\n",
        "max_db : 100\n",
        "ref_db : 20\n",
        "\n",
        "cleaners : \"english_cleaners\"\n",
        "\n",
        "data_path : \"./dataset/LJSpeech-1.1\"\n",
        "checkpoint_path : \"./checkpoint\"\n",
        "sample_path : \"./samples\"\n",
        "\n",
        "learning_rate: 0.0001\n",
        "weight_decay: 0.000001\n",
        "max_grad_norm: 1.0\n",
        "# batch_size: 32\n",
        "num_workers_train: 32\n",
        "num_workers_valid: 4\n",
        "betas: [0.9, 0.98]\n",
        "\n",
        "lexicon:\n",
        "    - AA\n",
        "    - AE\n",
        "    - AH\n",
        "    - AO\n",
        "    - AW\n",
        "    - AY\n",
        "    - B\n",
        "    - CH\n",
        "    - D\n",
        "    - DH\n",
        "    - EH\n",
        "    - ER\n",
        "    - EY\n",
        "    - F\n",
        "    - G\n",
        "    - HH\n",
        "    - IH\n",
        "    - IY\n",
        "    - JH\n",
        "    - K\n",
        "    - L\n",
        "    - M\n",
        "    - N\n",
        "    - NG\n",
        "    - OW\n",
        "    - OY\n",
        "    - P\n",
        "    - R\n",
        "    - S\n",
        "    - SH\n",
        "    - T\n",
        "    - TH\n",
        "    - UH\n",
        "    - UW\n",
        "    - V\n",
        "    - W\n",
        "    - Y\n",
        "    - Z\n",
        "    - ZH\n",
        "    - spn\n",
        "\n",
        "n_symbols: 42\n",
        "padding_idx: 0\n",
        "\n",
        "\n",
        "enc_num_layers: 4\n",
        "enc_num_head: 2\n",
        "enc_d_model: 384\n",
        "enc_ffn_dim: 1024\n",
        "enc_k_dim: 384\n",
        "enc_v_dim: 384\n",
        "enc_dropout: 0.2\n",
        "\n",
        "\n",
        "dec_num_layers: 4\n",
        "dec_num_head: 2\n",
        "dec_d_model: 384\n",
        "dec_ffn_dim: 1024\n",
        "dec_k_dim: 384\n",
        "dec_v_dim: 384\n",
        "dec_dropout: 0.2\n",
        "\n",
        "postnet_embedding_dim: 512\n",
        "postnet_kernel_size: 5\n",
        "postnet_n_convolutions: 5\n",
        "postnet_dropout: 0.5\n",
        "\n",
        "normalize_before: True\n",
        "ffn_type: 1dcnn\n",
        "ffn_cnn_kernel_size_list: [9, 1]\n",
        "\n",
        "\n",
        "dur_pred_kernel_size: 3\n",
        "pitch_pred_kernel_size: 3\n",
        "energy_pred_kernel_size: 3\n",
        "variance_predictor_dropout: 0.5\n",
        "\n",
        "model: !new:TransformersTTS.Model\n",
        "\n",
        "\n",
        "\n",
        "mel_spectogram: !name:speechbrain.lobes.models.FastSpeech2.mel_spectogram\n",
        "    sample_rate: !ref <sample_rate>\n",
        "    hop_length: !ref <hop_length>\n",
        "    win_length: !ref <win_length>\n",
        "    n_fft: !ref <n_fft>\n",
        "    n_mels: !ref <n_mel_channels>\n",
        "    f_min: !ref <mel_fmin>\n",
        "    f_max: !ref <mel_fmax>\n",
        "    power: !ref <power>\n",
        "    normalized: !ref <mel_normalized>\n",
        "    min_max_energy_norm: !ref <min_max_energy_norm>\n",
        "    norm: !ref <norm>\n",
        "    mel_scale: !ref <mel_scale>\n",
        "    compression: !ref <dynamic_range_compression>\n",
        "\n",
        "criterion: !new:utils.Loss\n",
        "    ssim_loss_weight: 1.0\n",
        "    mel_loss_weight: 1.0\n",
        "    postnet_mel_loss_weight: 1.0\n",
        "\n",
        "\n",
        "vocoder: \"hifi-gan\"\n",
        "pretrained_vocoder: True\n",
        "vocoder_source: speechbrain/tts-hifigan-ljspeech\n",
        "vocoder_download_path: tmpdir_vocoder\n",
        "\n",
        "modules:\n",
        "    model: !ref <model>\n",
        "\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    drop_last: False\n",
        "    num_workers: !ref <num_workers_train>\n",
        "    shuffle: True\n",
        "    collate_fn: !new:utils.TextMelAlignmentCollator\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    num_workers: !ref <num_workers_valid>\n",
        "    shuffle: False\n",
        "    collate_fn: !new:utils.TextMelAlignmentCollator\n",
        "\n",
        "opt_class: !name:torch.optim.Adam\n",
        "    lr: !ref <learning_rate>\n",
        "    weight_decay: !ref <weight_decay>\n",
        "    betas: !ref <betas>\n",
        "\n",
        "noam_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler\n",
        "    lr_initial: !ref <learning_rate>\n",
        "    n_warmup_steps: 4000\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <epochs>\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        lr_annealing: !ref <noam_annealing>\n",
        "        counter: !ref <epoch_counter>\n",
        "\n",
        "input_encoder: !new:speechbrain.dataio.encoder.TextEncoder\n",
        "\n",
        "progress_sample_logger: !new:speechbrain.utils.train_logger.ProgressSampleLogger\n",
        "    output_path: !ref <progress_sample_path>\n",
        "    batch_sample_size: !ref <progress_batch_sample_size>\n",
        "    formats:\n",
        "        raw_batch: raw"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script, `tts_train.py`, is responsible for training a TransformerTTS model for text-to-speech (TTS) synthesis. Let's break down its functionality:\n",
        "\n",
        "* The file handles GraphemeToPhoneme functionality. It defines the forward pass, loss computation, and batch processing functions. Additionally, it handles model inference and audio generation during training.\n",
        "\n",
        "* The `dataio_prepare` function prepares the datasets for training. It loads lexicon, encodes text and audio, and preprocesses mel spectrograms for input.\n",
        "\n",
        "* The `main` function is the entry point of the script. It parses command-line arguments, loads hyperparameters from a YAML file, and sets up the experiment directory. Then, it prepares the datasets, initializes the FastSpeech2Brain instance, and starts the training loop.\n",
        "\n",
        "* Inside the `main` function, the `fit` method of the model instance is called to train the model. It iterates over the training and validation datasets for the specified number of epochs, logging statistics and saving checkpoints periodically.\n",
        "\n",
        "* As you can predict we reuse a lot of fastspeech module for our purpose but modify it sufficiently to Accommodate our Transformer model.\n"
      ],
      "metadata": {
        "id": "U9lv3faHBFvM"
      },
      "id": "U9lv3faHBFvM"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8cd16c19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cd16c19",
        "outputId": "af4ebaae-d74b-4580-c002-1ff023ad631e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tts_train.py\n"
          ]
        }
      ],
      "source": [
        "%%file tts_train.py\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import speechbrain as sb\n",
        "from speechbrain.inference.vocoders import HIFIGAN\n",
        "from pathlib import Path\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from speechbrain.utils.data_utils import scalarize\n",
        "from speechbrain.inference.text import GraphemeToPhoneme\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class FastSpeech2Brain(sb.Brain):\n",
        "    def on_fit_start(self):\n",
        "        \"\"\"Gets called at the beginning of ``fit()``, on multiple processes\n",
        "        if ``distributed_count > 0`` and backend is ddp and initializes statistics\n",
        "        \"\"\"\n",
        "        self.hparams.progress_sample_logger.reset()\n",
        "        self.last_epoch = 0\n",
        "        self.last_batch = None\n",
        "        self.last_loss_stats = {}\n",
        "        self.g2p = GraphemeToPhoneme.from_hparams(\"speechbrain/soundchoice-g2p\")\n",
        "        self.spn_token_encoded = (\n",
        "            self.input_encoder.encode_sequence_torch([\"spn\"]).int().item()\n",
        "        )\n",
        "        return super().on_fit_start()\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Computes the forward pass\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch: str\n",
        "            a single batch\n",
        "        stage: speechbrain.Stage\n",
        "            the training stage\n",
        "        Returns\n",
        "        -------\n",
        "        the model output\n",
        "        \"\"\"\n",
        "        inputs = self.batch_to_device(batch)\n",
        "\n",
        "        phonemes, input_lengths, pos_text, spectogram, spectogram_input, pos_mel, pos_text, mel_lengths, gate_padded, wavs, labels = inputs\n",
        "\n",
        "        ( mel_pred, postnet_pred, attn_probs, stop_preds,\n",
        "         attns_enc, attns_dec )  = self.hparams.model(phonemes, spectogram_input, pos_text, pos_mel)\n",
        "\n",
        "        return ( mel_pred, postnet_pred, attn_probs, stop_preds,\n",
        "         attns_enc, attns_dec )\n",
        "\n",
        "    def on_fit_batch_end(self, batch, outputs, loss, should_step):\n",
        "        \"\"\"At the end of the optimizer step, apply noam annealing.\"\"\"\n",
        "        if should_step:\n",
        "            self.hparams.noam_annealing(self.optimizer)\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
        "        Arguments\n",
        "        ---------\n",
        "        predictions : torch.Tensor\n",
        "            The model generated spectrograms and other metrics from `compute_forward`.\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            A one-element tensor used for backpropagating the gradient.\n",
        "        \"\"\"\n",
        "        x, metadata = self.batch_to_device(batch, return_metadata=True)\n",
        "        phonemes, input_lengths, pos_text, spectogram, spectogram_input, pos_mel, pos_text, mel_lengths, gate_padded, wavs, labels = x\n",
        "\n",
        "        gate_target = gate_padded[:, :mel_lengths.max().item()]\n",
        "\n",
        "        mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec = predictions\n",
        "\n",
        "        self.last_batch = [phonemes, spectogram, spectogram_input, pos_mel, pos_text, input_lengths, mel_lengths, gate_padded, wavs, labels]\n",
        "\n",
        "        self._remember_sample([phonemes, spectogram, spectogram_input, pos_mel, pos_text, input_lengths, mel_lengths, gate_padded, wavs, labels], predictions)\n",
        "\n",
        "        srcmask_inverted = ~self.get_mask_from_lengths(mel_lengths)\n",
        "        loss = self.hparams.criterion(\n",
        "            mel_pred, spectogram, postnet_pred, gate_target, stop_preds, mel_lengths, srcmask_inverted, self.hparams.epoch_counter.current\n",
        "        )\n",
        "        self.last_loss_stats[stage] = scalarize(loss)\n",
        "        return loss[\"total_loss\"]\n",
        "\n",
        "    def _remember_sample(self, batch, predictions):\n",
        "\n",
        "        (\n",
        "            phonemes, spectogram, spectogram_input, pos_mel, pos_text, input_lengths,  mel_lengths, gate_padded, wavs, labels\n",
        "        ) = batch\n",
        "        (\n",
        "            mel_pred, postnet_pred, attn_probs, stop_preds,\n",
        "         attns_enc, attns_dec\n",
        "        ) = predictions\n",
        "\n",
        "        self.hparams.progress_sample_logger.remember(\n",
        "            targe=self.process_mel(spectogram, mel_lengths),\n",
        "            outpu=self.process_mel(mel_pred, mel_lengths),\n",
        "            raw_batch=self.hparams.progress_sample_logger.get_batch_sample(\n",
        "                {\n",
        "                    \"tokens\": phonemes,\n",
        "                    \"input_lengths\": input_lengths,\n",
        "                    \"mel_target\": spectogram,\n",
        "                    \"pos_text\": pos_text,\n",
        "                    \"pos_mel\": pos_mel,\n",
        "                    \"spectrogram_input\": spectogram_input,\n",
        "                    \"mel_pred\": mel_pred,\n",
        "                    \"postnet_out\": postnet_pred,\n",
        "                    \"stop_preds\": stop_preds,\n",
        "                    \"gate_padded\":gate_padded,\n",
        "                    \"labels\": labels,\n",
        "                    \"wavs\": wavs,\n",
        "                }\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def process_mel(self, mel, len, index=0):\n",
        "\n",
        "        assert mel.dim() == 3\n",
        "        return torch.sqrt(torch.exp(mel[index][: len[index]]))\n",
        "\n",
        "    def get_mask_from_lengths(self,lengths):\n",
        "        max_len = torch.max(lengths).item()\n",
        "        ids = lengths.new_tensor(torch.arange(0, max_len)).to(self.device)\n",
        "        mask = (lengths.unsqueeze(1) <= ids).to(torch.bool).to(self.device)\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "\n",
        "        if stage == sb.Stage.VALID:\n",
        "\n",
        "            self.last_epoch = epoch\n",
        "            lr = self.hparams.noam_annealing.current_lr\n",
        "\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch\": epoch, \"lr\": lr},\n",
        "                train_stats=self.last_loss_stats[sb.Stage.TRAIN],\n",
        "                valid_stats=self.last_loss_stats[sb.Stage.VALID],\n",
        "            )\n",
        "            output_progress_sample = (\n",
        "                self.hparams.progress_samples\n",
        "                and epoch % self.hparams.progress_samples_interval == 0\n",
        "                and epoch >= self.hparams.progress_samples_min_run\n",
        "            )\n",
        "\n",
        "            if output_progress_sample:\n",
        "                logger.info(\"Saving predicted samples\")\n",
        "\n",
        "                self.hparams.progress_sample_logger.save(epoch)\n",
        "                self.run_inference()\n",
        "\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta=self.last_loss_stats[stage],\n",
        "                min_keys=[\"total_loss\"],\n",
        "            )\n",
        "\n",
        "        if stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=self.last_loss_stats[sb.Stage.TEST],\n",
        "            )\n",
        "\n",
        "    def run_inference(self):\n",
        "        \"\"\"Produces a sample in inference mode with predicted durations.\"\"\"\n",
        "        if self.last_batch is None:\n",
        "            return\n",
        "\n",
        "        tokens, mel, mel_input, pos_mel, pos_text, text_lengths, output_lengths, gate_padded, wavs, labels = self.last_batch\n",
        "\n",
        "        assert (\n",
        "            self.hparams.vocoder == \"hifi-gan\"\n",
        "            and self.hparams.pretrained_vocoder is True\n",
        "        ), \"Specified vocoder not supported yet\"\n",
        "        logger.info(\n",
        "            f\"Generating audio with pretrained {self.hparams.vocoder_source} vocoder\"\n",
        "        )\n",
        "        hifi_gan = HIFIGAN.from_hparams(\n",
        "            source=self.hparams.vocoder_source,\n",
        "            savedir=self.hparams.vocoder_download_path,\n",
        "        )\n",
        "\n",
        "        for j in range(2):\n",
        "            token = tokens[j].unsqueeze(0)\n",
        "            mel_input = torch.zeros([1,1, 80]).to(tokens.device)\n",
        "            pos_text = torch.arange(1, token.size(1)+1).unsqueeze(0)\n",
        "            pos_text = pos_text.to(tokens.device)\n",
        "            wav_name = wavs[j]\n",
        "\n",
        "            length = 0\n",
        "            pbar = tqdm(range(1023))\n",
        "            with torch.no_grad():\n",
        "                for i in pbar:\n",
        "                    mel_input = mel_input.transpose(1,2)\n",
        "                    pos_mel = torch.arange(1,mel_input.size(2)+1).unsqueeze(0).to(tokens.device)\n",
        "                    mel_pred, postnet_pred, attn, stop_token, _, attn_dec = self.hparams.model.forward(token, mel_input, pos_text, pos_mel)\n",
        "                    mel_input = torch.cat([mel_input, mel_pred[:,-1:,:].transpose(1,2)], dim=2)\n",
        "                    mel_input = mel_input.transpose(1,2)\n",
        "                    length = i\n",
        "                    if torch.sigmoid(stop_token[:, -1, :])>0.5:\n",
        "                        break\n",
        "            length = torch.LongTensor([i])\n",
        "            waveforms = hifi_gan.decode_batch(\n",
        "                mel_input.transpose(2, 1), length, self.hparams.hop_length\n",
        "            )\n",
        "            for idx, wav in enumerate(waveforms):\n",
        "                sample_type = 'with_spn'\n",
        "                path = os.path.join(\n",
        "                    self.hparams.progress_sample_path,\n",
        "                    str(self.last_epoch),\n",
        "                    f\"pred_{sample_type}_{Path(wav_name).stem}.wav\",\n",
        "                )\n",
        "                torchaudio.save(path, wav, self.hparams.sample_rate)\n",
        "\n",
        "    def run_vocoder(self, inference_mel, mel_lens, sample_type=\"\"):\n",
        "        \"\"\"Uses a pretrained vocoder to generate audio from predicted mel\n",
        "        spectogram. By default, uses speechbrain hifigan.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        inference_mel: torch.Tensor\n",
        "            predicted mel from fastspeech2 inference\n",
        "        mel_lens: torch.Tensor\n",
        "            predicted mel lengths from fastspeech2 inference\n",
        "            used to mask the noise from padding\n",
        "        sample_type: str\n",
        "            used for logging the type of the inference sample being generated\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \"\"\"\n",
        "        if self.last_batch is None:\n",
        "            return\n",
        "        phonemes, spectogram, spectogram_input, pos_mel, pos_text, input_lengths, mel_lengths, gate_padded, wavs, labels = self.last_batch\n",
        "\n",
        "        inference_mel = inference_mel[: self.hparams.progress_batch_sample_size]\n",
        "        mel_lens = mel_lens[0 : self.hparams.progress_batch_sample_size]\n",
        "        assert (\n",
        "            self.hparams.vocoder == \"hifi-gan\"\n",
        "            and self.hparams.pretrained_vocoder is True\n",
        "        ), \"Specified vocoder not supported yet\"\n",
        "        logger.info(\n",
        "            f\"Generating audio with pretrained {self.hparams.vocoder_source} vocoder\"\n",
        "        )\n",
        "        hifi_gan = HIFIGAN.from_hparams(\n",
        "            source=self.hparams.vocoder_source,\n",
        "            savedir=self.hparams.vocoder_download_path,\n",
        "        )\n",
        "        waveforms = hifi_gan.decode_batch(\n",
        "            inference_mel.transpose(2, 1), mel_lens, self.hparams.hop_length\n",
        "        )\n",
        "        for idx, wav in enumerate(waveforms):\n",
        "            path = os.path.join(\n",
        "                self.hparams.progress_sample_path,\n",
        "                str(self.last_epoch),\n",
        "                f\"pred_{sample_type}_{Path(wavs[idx]).stem}.wav\",\n",
        "            )\n",
        "            torchaudio.save(path, wav, self.hparams.sample_rate)\n",
        "\n",
        "    def batch_to_device(self, batch, return_metadata=False):\n",
        "        \"\"\"Transfers the batch to the target device\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch: tuple\n",
        "            the batch to use\n",
        "        return_metadata: bool\n",
        "            indicates whether the metadata should be returned\n",
        "        Returns\n",
        "        -------\n",
        "        batch: tuple\n",
        "            the batch on the correct device\n",
        "        \"\"\"\n",
        "\n",
        "        (\n",
        "            text,\n",
        "            mel,\n",
        "            mel_input,\n",
        "            pos_text,\n",
        "            pos_mel,\n",
        "            text_length,\n",
        "            output_length,\n",
        "            gate_padded,\n",
        "            wavs,\n",
        "            labels,\n",
        "\n",
        "        ) = batch\n",
        "\n",
        "        phonemes = text.to(self.device, non_blocking=True).long()\n",
        "        spectogram = mel.to(self.device, non_blocking=True).float()\n",
        "        spectogram_input = mel_input.to(self.device, non_blocking=True).float()\n",
        "        input_lengths = text_length.to(self.device, non_blocking=True).long()\n",
        "        pos_mel = pos_mel.to(self.device, non_blocking=True).long()\n",
        "        pos_text = pos_text.to(self.device, non_blocking=True).long()\n",
        "        mel_lengths = output_length.to(self.device, non_blocking=True).long()\n",
        "        gate_padded = gate_padded.to(self.device, non_blocking=True).float()\n",
        "\n",
        "        x = (phonemes, input_lengths, pos_text, spectogram, spectogram_input, pos_mel, pos_text, mel_lengths, gate_padded, wavs, labels )\n",
        "\n",
        "        metadata = (labels, wavs)\n",
        "        if return_metadata:\n",
        "            return x, metadata\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dataio_prepare(hparams):\n",
        "\n",
        "    lexicon = hparams[\"lexicon\"]\n",
        "    input_encoder = hparams.get(\"input_encoder\")\n",
        "\n",
        "    lexicon = [\"@@\"] + lexicon\n",
        "    input_encoder.update_from_iterable(lexicon, sequence_input=False)\n",
        "    input_encoder.add_unk()\n",
        "\n",
        "    @sb.utils.data_pipeline.takes( \"wav\", \"label_phoneme\", \"durations\", \"start\", \"end\", \"spn_labels\",\n",
        "                                      \"last_phoneme_flags\" )\n",
        "    @sb.utils.data_pipeline.provides(\"mel_text_pair\")\n",
        "    def audio_pipeline( wav, label_phoneme, dur, start, end, spn_labels, last_phoneme_flags, ):\n",
        "\n",
        "        durs = np.load(dur)\n",
        "        durs_seq = torch.from_numpy(durs).int()\n",
        "\n",
        "        label_phoneme = label_phoneme.strip()\n",
        "        label_phoneme = label_phoneme.split()\n",
        "        phoneme_seq = input_encoder.encode_sequence_torch(label_phoneme).int()\n",
        "\n",
        "        assert len(phoneme_seq) == len(\n",
        "            durs\n",
        "        ), f\"{len(phoneme_seq)}, {len(durs), len(label_phoneme)}, ({label_phoneme})\"\n",
        "\n",
        "\n",
        "        audio, fs = torchaudio.load(wav)\n",
        "\n",
        "        audio = audio.squeeze()\n",
        "        audio = audio[int(fs * start) : int(fs * end)]\n",
        "\n",
        "        mel, energy = hparams[\"mel_spectogram\"](audio=audio)\n",
        "\n",
        "        text_length = len(phoneme_seq)\n",
        "        pos_text = np.arange(1, text_length + 1)\n",
        "\n",
        "        pos_mel = np.arange(1, mel.shape[1] + 1)\n",
        "        num_mels = 80\n",
        "        mel_input = np.concatenate([np.zeros([num_mels, 1], np.float32), mel[:,:-1]], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        return (\n",
        "                    phoneme_seq,\n",
        "                    mel,\n",
        "                    mel_input,\n",
        "                    pos_text,\n",
        "                    pos_mel,\n",
        "                    text_length,\n",
        "        )\n",
        "\n",
        "    datasets = {}\n",
        "\n",
        "    for dataset in hparams[\"splits\"]:\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
        "            json_path=hparams[f\"{dataset}_json\"],\n",
        "            replacements={\"data_root\": hparams[\"data_folder\"]},\n",
        "            dynamic_items=[audio_pipeline],\n",
        "            output_keys=[\"mel_text_pair\", \"wav\", \"label\" ],\n",
        "        )\n",
        "    return datasets, input_encoder\n",
        "\n",
        "\n",
        "def main():\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "    sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    datasets, input_encoder = dataio_prepare(hparams)\n",
        "\n",
        "    fastspeech2_brain = FastSpeech2Brain(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"opt_class\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    fastspeech2_brain.input_encoder = input_encoder\n",
        "    fastspeech2_brain.fit(\n",
        "        fastspeech2_brain.hparams.epoch_counter,\n",
        "        datasets[\"train\"],\n",
        "        datasets[\"valid\"],\n",
        "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As used many times in our lab assignments we simply use the speechbrain architecture to run our training moduile to produce model checkpoints."
      ],
      "metadata": {
        "id": "Tw4UBi5NCrBT"
      },
      "id": "Tw4UBi5NCrBT"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bac90193",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bac90193",
        "outputId": "9f1ea900-91ff-4f66-fd6b-e86a1ee448d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results\n",
            "speechbrain.core - Info: max_grad_norm arg from hparam file is used\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - 9.0M trainable parameters in FastSpeech2Brain\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "speechbrain.utils.fetching - Fetch hyperparams.yaml: Using existing file/symlink in pretrained_models/GraphemeToPhoneme-9b27d6eb840bf95c5aedf15ae8ed1172/hyperparams.yaml.\n",
            "speechbrain.utils.fetching - Fetch custom.py: Delegating to Huggingface hub, source speechbrain/soundchoice-g2p.\n",
            "speechbrain.utils.fetching - Fetch model.ckpt: Using existing file/symlink in pretrained_models/GraphemeToPhoneme-9b27d6eb840bf95c5aedf15ae8ed1172/model.ckpt.\n",
            "speechbrain.utils.fetching - Fetch ctc_lin.ckpt: Using existing file/symlink in pretrained_models/GraphemeToPhoneme-9b27d6eb840bf95c5aedf15ae8ed1172/ctc_lin.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: model, ctc_lin\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "  0% 0/6 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/content/tts_train.py:133: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  ids = lengths.new_tensor(torch.arange(0, max_len)).to(self.device)\n",
            "100% 6/6 [00:10<00:00,  1.68s/it, train_loss=39.9]\n",
            "100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 1, lr: 1.25e-07 - train total_loss: 39.90, train ssim_loss: 7.94e-01, train mel_loss: 19.24, train postnet_mel_loss: 19.61, train gate_loss: 2.57e-01 - valid total_loss: 37.21, valid ssim_loss: 6.87e-01, valid mel_loss: 18.54, valid postnet_mel_loss: 17.67, valid gate_loss: 3.15e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/save/CKPT+2024-04-26+23-38-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 6/6 [00:08<00:00,  1.45s/it, train_loss=37.8]\n",
            "100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 2, lr: 2.75e-07 - train total_loss: 37.16, train ssim_loss: 5.89e-01, train mel_loss: 18.15, train postnet_mel_loss: 18.13, train gate_loss: 2.90e-01 - valid total_loss: 37.11, valid ssim_loss: 6.87e-01, valid mel_loss: 18.55, valid postnet_mel_loss: 17.59, valid gate_loss: 2.73e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/save/CKPT+2024-04-26+23-38-29+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/save/CKPT+2024-04-26+23-38-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            " 67% 4/6 [00:07<00:03,  1.89s/it, train_loss=38]\n",
            "speechbrain.core - Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/tts_train.py\", line 414, in <module>\n",
            "    main()\n",
            "  File \"/content/tts_train.py\", line 404, in main\n",
            "    fastspeech2_brain.fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/speechbrain/core.py\", line 1555, in fit\n",
            "    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/speechbrain/core.py\", line 1384, in _fit_train\n",
            "    loss = self.fit_batch(batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/speechbrain/core.py\", line 1191, in fit_batch\n",
            "    return loss.detach().cpu()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python tts_train.py --device='cuda:0' --data_folder=LJSpeech-1.1 hparams_tts.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some sample audio links at different stages of training.\n",
        "\n",
        "* At 250 epoch: https://drive.google.com/file/d/1ysT5gfXe6rVn3hUz0WVYrrLYnMuKvwXp/view?usp=sharing\n",
        "\n",
        "* At 500 epochs: https://drive.google.com/file/d/1L3POSMxfQjvXPJeglE4EeeBLu9fuQbBf/view?usp=sharing\n",
        "\n",
        "* At 750 epochs: https://drive.google.com/file/d/1Op7dlAEnPvv_wTAygNvbBx_yczzajyIF/view?usp=sharing\n",
        "\n",
        "* At 900 epochs: https://drive.google.com/file/d/1gnyHWbm6dVuPLjoTHdV_lmGiGFC7tma7/view?usp=sharing\n",
        "\n",
        "While the results may not be flawless due to minor mistakes in my codebase and approach, they still provide a solid foundation for further work. This experience has enhanced my understanding of working with transformer models, allowing me to refine my methods and improve future outcomes."
      ],
      "metadata": {
        "id": "UM4Lfv3tNug7"
      },
      "id": "UM4Lfv3tNug7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Module.\n",
        "\n",
        "Although time constraints preventing the implementation of a proper Hugging Face API, I've managed to create a functional inference API. This API allows you to obtain results by downloading the model checkpoint and generating the output. Below, I'll demonstrate how you can utilize this API to generate the desired results.\n",
        "\n",
        "Note: Please run the upper blocks as well to procure all the relevant code for model etc.\n",
        "\n",
        "The code below downloads the model checkpoint to run our inference."
      ],
      "metadata": {
        "id": "tKk07PPnDzyP"
      },
      "id": "tKk07PPnDzyP"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown 1geJ8ILZJNCEQJidKU-bChqmvcbESDdiO\n",
        "# https://drive.google.com/file/d/1geJ8ILZJNCEQJidKU-bChqmvcbESDdiO/view?usp=sharing"
      ],
      "metadata": {
        "id": "HvSn2PF6J8Hk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfbbfee-3e34-46f2-d5f6-33ec0084e674"
      },
      "id": "HvSn2PF6J8Hk",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1geJ8ILZJNCEQJidKU-bChqmvcbESDdiO\n",
            "From (redirected): https://drive.google.com/uc?id=1geJ8ILZJNCEQJidKU-bChqmvcbESDdiO&confirm=t&uuid=07bee924-1dd7-4bad-a5d1-fb78817d0121\n",
            "To: /content/model.ckpt\n",
            "100% 38.0M/38.0M [00:00<00:00, 75.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This piece of code essentially runs a text-to-speech model, using a transformer-based approach. First, it sets up the necessary tools like the HIFIGAN vocoder and a text converter. Then, it prepares the input text by turning it into phonetic representations. After loading the model and its settings, it encodes the text into tokens and starts generating speech. The model keeps predicting mel-spectrogram frames until it decides to stop, determining the length of the generated audio. Finally, it uses the HIFIGAN vocoder to convert these mel-spectrograms into actual audio files, saving them in a folder named 'infoutput'."
      ],
      "metadata": {
        "id": "9UPkQNpyMKKF"
      },
      "id": "9UPkQNpyMKKF"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from speechbrain.inference.text import GraphemeToPhoneme\n",
        "from speechbrain.inference.vocoders import HIFIGAN\n",
        "from TransformersTTS import Model\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def inference_run(input_text=\"This is the first test for my trasnformer model.\"):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    vocoder = HIFIGAN.from_hparams(source='speechbrain/tts-hifigan-ljspeech', savedir='tmpdir_vocoder')\n",
        "\n",
        "    hyperparameters_file = 'hparams_tts.yaml'\n",
        "    with open(hyperparameters_file) as f:\n",
        "        hyperparameters = load_hyperpyyaml(f, '')\n",
        "\n",
        "    grapheme_to_phoneme_converter = GraphemeToPhoneme.from_hparams(\"speechbrain/soundchoice-g2p\", savedir=\"pretrained_models/soundchoice-g2p\")\n",
        "    phonemes = grapheme_to_phoneme_converter.g2p(input_text)\n",
        "    phoneme_sequence = \" \".join(phonemes)\n",
        "\n",
        "    tts_model = Model().to(device)\n",
        "    checkpoint_path = 'model.ckpt'\n",
        "    tts_model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "    phoneme_sequence = phoneme_sequence.strip().split()\n",
        "    lexicon = [\"@@\"] + hyperparameters[\"lexicon\"]\n",
        "    input_encoder = hyperparameters.get(\"input_encoder\")\n",
        "    input_encoder.update_from_iterable(lexicon, sequence_input=False)\n",
        "    tokens = input_encoder.encode_sequence_torch(phoneme_sequence).int()\n",
        "\n",
        "    token_tensor = tokens.unsqueeze(0).to(device)\n",
        "    mel_input = torch.zeros([1, 1, 80]).to(token_tensor.device)\n",
        "    pos_text = torch.arange(1, token_tensor.size(1)+1).unsqueeze(0).to(token_tensor.device)\n",
        "\n",
        "    tts_model.eval()\n",
        "    max_length = 1023\n",
        "    pbar = tqdm(range(max_length))\n",
        "    with torch.no_grad():\n",
        "        for i in pbar:\n",
        "            mel_input = mel_input.transpose(1, 2)\n",
        "            pos_mel = torch.arange(1, mel_input.size(2)+1).unsqueeze(0).to(token_tensor.device)\n",
        "            mel_pred, postnet_pred, attn, stop_token, _, attn_dec = tts_model.forward(token_tensor, mel_input, pos_text, pos_mel)\n",
        "            mel_input = torch.cat([mel_input, mel_pred[:, -1:, :].transpose(1, 2)], dim=2)\n",
        "            mel_input = mel_input.transpose(1, 2)\n",
        "            length = i\n",
        "            if torch.sigmoid(stop_token[:, -1, :]) > 0.5:\n",
        "                break\n",
        "\n",
        "    length_tensor = torch.LongTensor([length]).to(device)\n",
        "\n",
        "    waveforms = vocoder.decode_batch(mel_input.transpose(2, 1), length_tensor, 256)\n",
        "    for idx, wav in enumerate(waveforms):\n",
        "        output_path = os.path.join('results', \"pred_sample.wav\")\n",
        "        torchaudio.save(output_path, wav, 22050)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    inference_run()\n",
        "\n",
        "# File is in the results folder with the name pred_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "42fcb1bc4f364734abb051de9cf0992d",
            "71c77550b8064f279384949b74e3a183",
            "fecb785128ae4c65977c7456b62e2c7d",
            "27edccf1805941d08cd2f7797e55c871",
            "9976be7e16c74f8aa494bd14cdb954f9",
            "0b2529d7778c47fc9586c2d9c9ee4a08",
            "064987961262411f945cadc03acc743c",
            "03439f80215446389ea5812da64f496d",
            "9adef0b4c4174db88f83c739263b4964",
            "65a0643ee00749b69301cb35c26626f7",
            "f02b7848f2e24f56a6f0a561e791b760",
            "378d3b0160164dc8a175e5b63137da68",
            "ccd370cd30ce4dd38635a360469b8ffc",
            "aa4cb023ac6a4eef8bddcc280b7c29f3",
            "1e15ce501371408080410cc090fb51f7",
            "35bf7fe91b274006acc597167d2bde0d",
            "284c29a624de42d5a1b28ed3724ac499",
            "56a8264422c34df99fee58e2efcec30d",
            "10de341d203449309705b117356f0a5a",
            "bee599a5800e441aaa493ab2597b34ec",
            "0eed413e54b94072ac7ae09767a96e17",
            "c711049ade254401936b3e7c2dec8a32"
          ]
        },
        "id": "6YS1-fTGH2LU",
        "outputId": "911b555c-ce58-49e0-b2a1-ad0bd58b603d"
      },
      "id": "6YS1-fTGH2LU",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "hyperparams.yaml:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42fcb1bc4f364734abb051de9cf0992d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generator.ckpt:   0%|          | 0.00/55.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "378d3b0160164dc8a175e5b63137da68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 264/1023 [00:05<00:15, 49.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here is the sample for default text**: https://drive.google.com/file/d/1H9COSeXNifkLLZf7gl4e1PB37l1MHHr2/view?usp=sharing"
      ],
      "metadata": {
        "id": "EykwtUxA1X8J"
      },
      "id": "EykwtUxA1X8J"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8eea731c792b44289d88139abf99856d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37fef45307f348c0baba4436d8caf288",
              "IPY_MODEL_5b3db8a91ec245b3910547e63a262363",
              "IPY_MODEL_880d89cb142b4018a3ce6090c0836c77"
            ],
            "layout": "IPY_MODEL_6f8a2703ef80484d81f0b2a33e5a26b8"
          }
        },
        "37fef45307f348c0baba4436d8caf288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0fd2fbef4224e97987122e4ecee9061",
            "placeholder": "​",
            "style": "IPY_MODEL_eab08aca599b42b7a80eb614893bad28",
            "value": "hyperparams.yaml: 100%"
          }
        },
        "5b3db8a91ec245b3910547e63a262363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88ad9961864943e4a6b71189d5610a3c",
            "max": 11324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bb90181c5884402ae74ce1c806e654f",
            "value": 11324
          }
        },
        "880d89cb142b4018a3ce6090c0836c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed574c637f1a4d969afdc7d4a6e03aef",
            "placeholder": "​",
            "style": "IPY_MODEL_ee3ef5bb3015474b921a8ac7658538c1",
            "value": " 11.3k/11.3k [00:00&lt;00:00, 471kB/s]"
          }
        },
        "6f8a2703ef80484d81f0b2a33e5a26b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0fd2fbef4224e97987122e4ecee9061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab08aca599b42b7a80eb614893bad28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ad9961864943e4a6b71189d5610a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb90181c5884402ae74ce1c806e654f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed574c637f1a4d969afdc7d4a6e03aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3ef5bb3015474b921a8ac7658538c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2b7694d43f14b0bb0cfb13267099003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cd23a012a4f46dbb3a81fae3794fd18",
              "IPY_MODEL_52af0aaacec8454789afebd0eba9ab99",
              "IPY_MODEL_5d380d695e3343f7b5f937adbc5efa49"
            ],
            "layout": "IPY_MODEL_bb1372b1f61344bbb14221791eecdf26"
          }
        },
        "6cd23a012a4f46dbb3a81fae3794fd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d082baee57a74ee6bfae441aa8270cca",
            "placeholder": "​",
            "style": "IPY_MODEL_ed12c3392abc4ff0abdd28eedfbf1a74",
            "value": "model.ckpt: 100%"
          }
        },
        "52af0aaacec8454789afebd0eba9ab99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f02f630405740f885668263a05e2f50",
            "max": 128643257,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad44ba91795d40e498ccc8200e5464cd",
            "value": 128643257
          }
        },
        "5d380d695e3343f7b5f937adbc5efa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_424b6e22f9b445cb91679c74d85fdf5b",
            "placeholder": "​",
            "style": "IPY_MODEL_26628264149341788b59e90dc86db726",
            "value": " 129M/129M [00:02&lt;00:00, 58.4MB/s]"
          }
        },
        "bb1372b1f61344bbb14221791eecdf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d082baee57a74ee6bfae441aa8270cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed12c3392abc4ff0abdd28eedfbf1a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f02f630405740f885668263a05e2f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad44ba91795d40e498ccc8200e5464cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "424b6e22f9b445cb91679c74d85fdf5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26628264149341788b59e90dc86db726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7372719780404a2a84809a0a37db7e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48eaf4b78c96419a8a85ac5a8841ead4",
              "IPY_MODEL_06f38e64742a48f99c7bd1497e067e4c",
              "IPY_MODEL_61c65f8590664b388fd1ed13ef61f488"
            ],
            "layout": "IPY_MODEL_6666efb651cb4283aa5d5635c1d49334"
          }
        },
        "48eaf4b78c96419a8a85ac5a8841ead4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b24732d0794a3692e224c2592747c9",
            "placeholder": "​",
            "style": "IPY_MODEL_78319c6771ec4a3c930df7e3a813a72d",
            "value": "ctc_lin.ckpt: 100%"
          }
        },
        "06f38e64742a48f99c7bd1497e067e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36e07edc60394830bb3d936fa9de2704",
            "max": 177319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be09730a704f44eba1131670a03c42a6",
            "value": 177319
          }
        },
        "61c65f8590664b388fd1ed13ef61f488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9083058889cb4ca6ad2cec05f4213626",
            "placeholder": "​",
            "style": "IPY_MODEL_56ef28a46a184bb19c0b4b0c04503bbf",
            "value": " 177k/177k [00:00&lt;00:00, 2.72MB/s]"
          }
        },
        "6666efb651cb4283aa5d5635c1d49334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b24732d0794a3692e224c2592747c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78319c6771ec4a3c930df7e3a813a72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e07edc60394830bb3d936fa9de2704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be09730a704f44eba1131670a03c42a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9083058889cb4ca6ad2cec05f4213626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ef28a46a184bb19c0b4b0c04503bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54a23b5f818b4498a18a9fe59fedcc6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45708e95ab1e42ab852aeb8ec5fb42b7",
              "IPY_MODEL_7bd454536a114446937311d9befaf020",
              "IPY_MODEL_4938ce874ba24893b3aa4955ff8ac111"
            ],
            "layout": "IPY_MODEL_ac86644e6923417bbd570c2b1ed35fa6"
          }
        },
        "45708e95ab1e42ab852aeb8ec5fb42b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ac4ba4fc784b549e5073a452624ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_75e4d74346a34460a9a6c8e6fd25b713",
            "value": "config.json: 100%"
          }
        },
        "7bd454536a114446937311d9befaf020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d8e9b56d494312bd440341ea0a4b05",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d8e6e13d732408a9c1a006201f7c8d8",
            "value": 570
          }
        },
        "4938ce874ba24893b3aa4955ff8ac111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ac6771c51c4c7d9a49c8c6a468c774",
            "placeholder": "​",
            "style": "IPY_MODEL_4b735ce6a5ca404699cae415e6ff923f",
            "value": " 570/570 [00:00&lt;00:00, 37.1kB/s]"
          }
        },
        "ac86644e6923417bbd570c2b1ed35fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ac4ba4fc784b549e5073a452624ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e4d74346a34460a9a6c8e6fd25b713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d8e9b56d494312bd440341ea0a4b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d8e6e13d732408a9c1a006201f7c8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6ac6771c51c4c7d9a49c8c6a468c774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b735ce6a5ca404699cae415e6ff923f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e6c899da7034b56a982da7787f1edeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba978c7319bf44d8967b58e2b3c255d1",
              "IPY_MODEL_3b6f3ccb9ccd4bc9b83458842bc15b65",
              "IPY_MODEL_22ebec9e4711433ea8cee13031339633"
            ],
            "layout": "IPY_MODEL_623e0768b5bc4346abeff0f7699dacdb"
          }
        },
        "ba978c7319bf44d8967b58e2b3c255d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c556f9e74d124c14826778d4fa90d979",
            "placeholder": "​",
            "style": "IPY_MODEL_c0cc3fcd40944fef8da047c7cec0f5a4",
            "value": "model.safetensors: 100%"
          }
        },
        "3b6f3ccb9ccd4bc9b83458842bc15b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d0c66f1f3a4ebeb122304f6e53fc78",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3471f27bc5774c98a25c4b8d3eead176",
            "value": 440449768
          }
        },
        "22ebec9e4711433ea8cee13031339633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e701627f721a4756b567f144bc6aa93f",
            "placeholder": "​",
            "style": "IPY_MODEL_3886ccc4af464a8087f581da8a8b1efa",
            "value": " 440M/440M [00:01&lt;00:00, 244MB/s]"
          }
        },
        "623e0768b5bc4346abeff0f7699dacdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c556f9e74d124c14826778d4fa90d979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0cc3fcd40944fef8da047c7cec0f5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96d0c66f1f3a4ebeb122304f6e53fc78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3471f27bc5774c98a25c4b8d3eead176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e701627f721a4756b567f144bc6aa93f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3886ccc4af464a8087f581da8a8b1efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "710c51edb33a48649d5d4dc95d093280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75e2e2cbfc9d4397980c536c53a1f9c3",
              "IPY_MODEL_acf390c4ddd741bd98a4dc1466eecb04",
              "IPY_MODEL_4c165c25e4234966ba508baa7eb9d737"
            ],
            "layout": "IPY_MODEL_14b29ecfe2034a8a9c36235ecb87eb69"
          }
        },
        "75e2e2cbfc9d4397980c536c53a1f9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c19277b152ae45a9b5dd01ce6ff90fa7",
            "placeholder": "​",
            "style": "IPY_MODEL_0b5d2cda6a1b499c807c1f46e35bf0eb",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "acf390c4ddd741bd98a4dc1466eecb04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6450e72a35cb4bf8b415fb2c6c48e93b",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_734372c1d3874a1ca6b18267b4eb1d9a",
            "value": 48
          }
        },
        "4c165c25e4234966ba508baa7eb9d737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ae94a2687944e493b5d30e6f47d934",
            "placeholder": "​",
            "style": "IPY_MODEL_2e05bfe6b97d4df99f200e9eb647bb15",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.44kB/s]"
          }
        },
        "14b29ecfe2034a8a9c36235ecb87eb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19277b152ae45a9b5dd01ce6ff90fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5d2cda6a1b499c807c1f46e35bf0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6450e72a35cb4bf8b415fb2c6c48e93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734372c1d3874a1ca6b18267b4eb1d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9ae94a2687944e493b5d30e6f47d934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e05bfe6b97d4df99f200e9eb647bb15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0855f061a75f4e75a420285277da293a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8c7d857db1e4335af1db4c1a5e09c98",
              "IPY_MODEL_aa8c130dbd7145068ca0aa2fc2c548e4",
              "IPY_MODEL_eafe835f5127474bb8b5c1f99b2f5e03"
            ],
            "layout": "IPY_MODEL_a0f08e92309c4f15ae0836efdcd6bee7"
          }
        },
        "a8c7d857db1e4335af1db4c1a5e09c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b72cef7b7c3a414e8374bec36a5ddd82",
            "placeholder": "​",
            "style": "IPY_MODEL_e45d74cac99344fcbb96d2541881db36",
            "value": "vocab.txt: 100%"
          }
        },
        "aa8c130dbd7145068ca0aa2fc2c548e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804b885f2b0b48bda134b029804145d8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae79700edf90484382ea3c4f053bfc40",
            "value": 231508
          }
        },
        "eafe835f5127474bb8b5c1f99b2f5e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a03afcb5961428bb6bab96a06b5c890",
            "placeholder": "​",
            "style": "IPY_MODEL_622df8151d8e4fc7afe758813cfb5e53",
            "value": " 232k/232k [00:00&lt;00:00, 10.4MB/s]"
          }
        },
        "a0f08e92309c4f15ae0836efdcd6bee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72cef7b7c3a414e8374bec36a5ddd82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45d74cac99344fcbb96d2541881db36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "804b885f2b0b48bda134b029804145d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae79700edf90484382ea3c4f053bfc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a03afcb5961428bb6bab96a06b5c890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622df8151d8e4fc7afe758813cfb5e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "871cd0d5855d4173934f11505692f77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be5229b11b92408595e3a184a2689c21",
              "IPY_MODEL_03e8d58719f4464e9864c6ee22942e24",
              "IPY_MODEL_bb322f0a51664a238d92db22d36efb9f"
            ],
            "layout": "IPY_MODEL_65b4aa1ceb7043438e5432e335f485ef"
          }
        },
        "be5229b11b92408595e3a184a2689c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_149be4952a294c01b41604c177fea35a",
            "placeholder": "​",
            "style": "IPY_MODEL_86b078fa896148a09832940f4102601f",
            "value": "tokenizer.json: 100%"
          }
        },
        "03e8d58719f4464e9864c6ee22942e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8122674de4a4f92a254beb29c76425a",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0ddd4a70cc2422ca9edc860d670dd0d",
            "value": 466062
          }
        },
        "bb322f0a51664a238d92db22d36efb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4254f0e74b141c7a0d91f3b7e5889fb",
            "placeholder": "​",
            "style": "IPY_MODEL_b4770617dc3b47eeb20925cba974bcef",
            "value": " 466k/466k [00:00&lt;00:00, 1.06MB/s]"
          }
        },
        "65b4aa1ceb7043438e5432e335f485ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149be4952a294c01b41604c177fea35a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b078fa896148a09832940f4102601f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8122674de4a4f92a254beb29c76425a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ddd4a70cc2422ca9edc860d670dd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4254f0e74b141c7a0d91f3b7e5889fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4770617dc3b47eeb20925cba974bcef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42fcb1bc4f364734abb051de9cf0992d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71c77550b8064f279384949b74e3a183",
              "IPY_MODEL_fecb785128ae4c65977c7456b62e2c7d",
              "IPY_MODEL_27edccf1805941d08cd2f7797e55c871"
            ],
            "layout": "IPY_MODEL_9976be7e16c74f8aa494bd14cdb954f9"
          }
        },
        "71c77550b8064f279384949b74e3a183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2529d7778c47fc9586c2d9c9ee4a08",
            "placeholder": "​",
            "style": "IPY_MODEL_064987961262411f945cadc03acc743c",
            "value": "hyperparams.yaml: 100%"
          }
        },
        "fecb785128ae4c65977c7456b62e2c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03439f80215446389ea5812da64f496d",
            "max": 1156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9adef0b4c4174db88f83c739263b4964",
            "value": 1156
          }
        },
        "27edccf1805941d08cd2f7797e55c871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a0643ee00749b69301cb35c26626f7",
            "placeholder": "​",
            "style": "IPY_MODEL_f02b7848f2e24f56a6f0a561e791b760",
            "value": " 1.16k/1.16k [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "9976be7e16c74f8aa494bd14cdb954f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2529d7778c47fc9586c2d9c9ee4a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064987961262411f945cadc03acc743c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03439f80215446389ea5812da64f496d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9adef0b4c4174db88f83c739263b4964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65a0643ee00749b69301cb35c26626f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02b7848f2e24f56a6f0a561e791b760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "378d3b0160164dc8a175e5b63137da68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd370cd30ce4dd38635a360469b8ffc",
              "IPY_MODEL_aa4cb023ac6a4eef8bddcc280b7c29f3",
              "IPY_MODEL_1e15ce501371408080410cc090fb51f7"
            ],
            "layout": "IPY_MODEL_35bf7fe91b274006acc597167d2bde0d"
          }
        },
        "ccd370cd30ce4dd38635a360469b8ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284c29a624de42d5a1b28ed3724ac499",
            "placeholder": "​",
            "style": "IPY_MODEL_56a8264422c34df99fee58e2efcec30d",
            "value": "generator.ckpt: 100%"
          }
        },
        "aa4cb023ac6a4eef8bddcc280b7c29f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10de341d203449309705b117356f0a5a",
            "max": 55828077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bee599a5800e441aaa493ab2597b34ec",
            "value": 55828077
          }
        },
        "1e15ce501371408080410cc090fb51f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eed413e54b94072ac7ae09767a96e17",
            "placeholder": "​",
            "style": "IPY_MODEL_c711049ade254401936b3e7c2dec8a32",
            "value": " 55.8M/55.8M [00:03&lt;00:00, 21.7MB/s]"
          }
        },
        "35bf7fe91b274006acc597167d2bde0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "284c29a624de42d5a1b28ed3724ac499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a8264422c34df99fee58e2efcec30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10de341d203449309705b117356f0a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee599a5800e441aaa493ab2597b34ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0eed413e54b94072ac7ae09767a96e17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c711049ade254401936b3e7c2dec8a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}